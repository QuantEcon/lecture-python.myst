

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>11. LLN and CLT &#8212; Intermediate Quantitative Economics with Python</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/quantecon-book-theme.css?digest=b09b2da44b9015b4fa76ea072fa2d8f7faee5492" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>


    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/scripts/quantecon-book-theme.js?digest=eed9c059a3ee152aae2353ec732f0a6d12e6aa07"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-J0SMYR4SG3"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-J0SMYR4SG3');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "arg\\,max", "argmin": "arg\\,min"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lln_clt';</script>
    <link rel="canonical" href="https://python.quantecon.org/lln_clt.html" />
    <link rel="shortcut icon" href="_static/lectures-favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="12. Two Meanings of Probability" href="prob_meaning.html" />
    <link rel="prev" title="10. Elementary Probability with Matrices" href="prob_matrix.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Python, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="LLN and CLT"/>
<meta name="twitter:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="LLN and CLT" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://python.quantecon.org/lln_clt.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski." />
<meta property="og:site_name" content="Intermediate Quantitative Economics with Python" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=lln_clt>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">11.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relationships">11.2. Relationships</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lln">11.3. LLN</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-classical-lln">11.3.1. The Classical LLN</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#proof">11.3.2. Proof</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#illustration">11.3.3. Illustration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clt">11.4. CLT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#statement-of-the-theorem">11.4.1. Statement of the Theorem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intuition">11.4.2. Intuition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-1">11.4.3. Simulation 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simulation-2">11.4.4. Simulation 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-multivariate-case">11.4.5. The Multivariate Case</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">11.5. Exercises</a></li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="_static/qe-logo-large.png" class="logo logo-img" alt="logo"></a>
                                    
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="intro.html">Intermediate Quantitative Economics with Python</a></p>

                        <p class="qe-page__header-subheading">LLN and CLT</p>

                    </div>
                    <!-- length 2, since its a string and empty dict has length 2 - {} -->
                        <p class="qe-page__header-authors" font-size="18">
                            
                                
                                    <a href="http://www.tomsargent.com/" target="_blank"><span>Thomas J. Sargent</span></a>
                                
                            
                                
                                    and <a href="https://johnstachurski.net/" target="_blank"><span>John Stachurski</span></a>
                                
                            
                        </p>


                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <div id="qe-notebook-header" align="right" style="text-align:right;">
        <a href="https://quantecon.org/" title="quantecon.org">
                <img style="width:250px;display:inline;" width="250px" src="https://assets.quantecon.org/img/qe-menubar-logo.svg" alt="QuantEcon">
        </a>
</div><section class="tex2jax_ignore mathjax_ignore" id="lln-and-clt">
<h1><a class="toc-backref" href="#id3"><span class="section-number">11. </span><span class="target" id="index-0"></span>LLN and <span class="target" id="index-1"></span>CLT</a><a class="headerlink" href="#lln-and-clt" title="Permalink to this heading">#</a></h1>
<span class="target" id="index-2"></span><div class="contents topic" id="contents">
<span id="index-3"></span><p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#lln-and-clt" id="id3">LLN and CLT</a></p>
<ul>
<li><p><a class="reference internal" href="#overview" id="id4">Overview</a></p></li>
<li><p><a class="reference internal" href="#relationships" id="id5">Relationships</a></p></li>
<li><p><a class="reference internal" href="#lln" id="id6">LLN</a></p></li>
<li><p><a class="reference internal" href="#clt" id="id7">CLT</a></p></li>
<li><p><a class="reference internal" href="#exercises" id="id8">Exercises</a></p></li>
</ul>
</li>
</ul>
</div>
<section id="overview">
<h2><a class="toc-backref" href="#id4"><span class="section-number">11.1. </span>Overview</a><a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>This lecture illustrates two of the most important theorems of probability and statistics: The
law of large numbers (LLN) and the central limit theorem (CLT).</p>
<p>These beautiful theorems lie behind many of the most fundamental results in econometrics and quantitative economic modeling.</p>
<p>The lecture is based around simulations that show the LLN and CLT in action.</p>
<p>We also demonstrate how the LLN and CLT break down when the assumptions they are based on do not hold.</p>
<p>In addition, we examine several useful extensions of the classical theorems, such as</p>
<ul class="simple">
<li><p>The delta method, for smooth functions of random variables, and</p></li>
<li><p>the multivariate case.</p></li>
</ul>
<p>Some of these extensions are presented as exercises.</p>
<p>We’ll need the following imports:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>  <span class="c1">#set default figure size</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">t</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">lognorm</span><span class="p">,</span> <span class="n">expon</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">uniform</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">gaussian_kde</span><span class="p">,</span> <span class="n">poisson</span><span class="p">,</span> <span class="n">binom</span><span class="p">,</span> <span class="n">norm</span><span class="p">,</span> <span class="n">chi2</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span> <span class="nn">matplotlib.collections</span> <span class="kn">import</span> <span class="n">PolyCollection</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">inv</span><span class="p">,</span> <span class="n">sqrtm</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="relationships">
<h2><a class="toc-backref" href="#id5"><span class="section-number">11.2. </span>Relationships</a><a class="headerlink" href="#relationships" title="Permalink to this heading">#</a></h2>
<p>The CLT refines the LLN.</p>
<p>The LLN gives conditions under which sample moments converge to population moments as sample size increases.</p>
<p>The CLT provides information about the rate at which sample moments converge to population moments as sample size increases.</p>
</section>
<section id="lln">
<span id="lln-mr"></span><h2><a class="toc-backref" href="#id6"><span class="section-number">11.3. </span>LLN</a><a class="headerlink" href="#lln" title="Permalink to this heading">#</a></h2>
<p id="index-4">We begin with the law of large numbers, which tells us when sample averages
will converge to their population means.</p>
<section id="the-classical-lln">
<span id="lln-ksl"></span><h3><span class="section-number">11.3.1. </span>The Classical LLN<a class="headerlink" href="#the-classical-lln" title="Permalink to this heading">#</a></h3>
<p>The classical law of large numbers concerns independent and
identically distributed (IID) random variables.</p>
<p>Here is the strongest version of the classical LLN, known as <em>Kolmogorov’s strong law</em>.</p>
<p>Let <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> be independent and identically
distributed scalar random variables, with common distribution <span class="math notranslate nohighlight">\(F\)</span>.</p>
<p>When it exists, let <span class="math notranslate nohighlight">\(\mu\)</span> denote the common mean of this sample:</p>
<div class="math notranslate nohighlight">
\[
\mu := \mathbb E X = \int x F(dx)
\]</div>
<p>In addition, let</p>
<div class="math notranslate nohighlight">
\[
\bar X_n := \frac{1}{n} \sum_{i=1}^n X_i
\]</div>
<p>Kolmogorov’s strong law states that, if <span class="math notranslate nohighlight">\(\mathbb E |X|\)</span> is finite, then</p>
<div class="math notranslate nohighlight" id="equation-lln-as">
<span class="eqno">(11.1)<a class="headerlink" href="#equation-lln-as" title="Permalink to this equation">#</a></span>\[\mathbb P \left\{ \bar X_n \to \mu \text{ as } n \to \infty \right\} = 1\]</div>
<p>What does this last expression mean?</p>
<p>Let’s think about it from a simulation perspective, imagining for a moment that
our computer can generate perfect random samples (which of course <a class="reference external" href="https://en.wikipedia.org/wiki/Pseudorandom_number_generator">it can’t</a>).</p>
<p>Let’s also imagine that we can generate infinite sequences so that the
statement <span class="math notranslate nohighlight">\(\bar X_n \to \mu\)</span> can be evaluated.</p>
<p>In this setting, <a class="reference internal" href="#equation-lln-as">(11.1)</a> should be interpreted as meaning that the
probability of the computer producing a sequence where <span class="math notranslate nohighlight">\(\bar X_n \to \mu\)</span> fails to occur
is zero.</p>
</section>
<section id="proof">
<h3><span class="section-number">11.3.2. </span>Proof<a class="headerlink" href="#proof" title="Permalink to this heading">#</a></h3>
<p id="index-5">The proof of Kolmogorov’s strong law is nontrivial – see, for example, theorem 8.3.5 of <span id="id1">[<a class="reference internal" href="zreferences.html#id158" title="R M Dudley. Real Analysis and Probability. Cambridge Studies in Advanced Mathematics. Cambridge University Press, 2002.">Dud02</a>]</span>.</p>
<p>On the other hand, we can prove a weaker version of the LLN very easily and
still get most of the intuition.</p>
<p>The version we prove is as follows: If <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> is IID with <span class="math notranslate nohighlight">\(\mathbb E X_i^2 &lt; \infty\)</span>,
then, for any <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, we have</p>
<div class="math notranslate nohighlight" id="equation-lln-ip">
<span class="eqno">(11.2)<a class="headerlink" href="#equation-lln-ip" title="Permalink to this equation">#</a></span>\[\mathbb P \left\{ | \bar X_n - \mu | \geq \epsilon \right\} \to 0
\quad \text{as} \quad
n \to \infty\]</div>
<p>(This version is weaker because we claim only <a class="reference external" href="https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_probability">convergence in probability</a> rather than <a class="reference external" href="https://en.wikipedia.org/wiki/Convergence_of_random_variables#Almost_sure_convergence">almost sure convergence</a>, and assume a finite second moment)</p>
<p>To see that this is so, fix <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>, and let <span class="math notranslate nohighlight">\(\sigma^2\)</span> be the variance of each <span class="math notranslate nohighlight">\(X_i\)</span>.</p>
<p>Recall the <a class="reference external" href="https://en.wikipedia.org/wiki/Chebyshev%27s_inequality">Chebyshev inequality</a>, which tells us that</p>
<div class="math notranslate nohighlight" id="equation-lln-cheb">
<span class="eqno">(11.3)<a class="headerlink" href="#equation-lln-cheb" title="Permalink to this equation">#</a></span>\[\mathbb P \left\{ | \bar X_n - \mu | \geq \epsilon \right\}
\leq \frac{\mathbb E [ (\bar X_n - \mu)^2]}{\epsilon^2}\]</div>
<p>Now observe that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    \mathbb E [ (\bar X_n - \mu)^2 ]
    &amp; = \mathbb E \left\{ \left[
    \frac{1}{n} \sum_{i=1}^n (X_i - \mu)
    \right]^2 \right\}
    \\
    &amp; = \frac{1}{n^2} \sum_{i=1}^n \sum_{j=1}^n \mathbb E (X_i - \mu)(X_j - \mu) \nonumber
    \\
    &amp; = \frac{1}{n^2} \sum_{i=1}^n \mathbb E (X_i - \mu)^2 \nonumber
    \\
    &amp; = \frac{\sigma^2}{n} \nonumber
\end{aligned}
\end{split}\]</div>
<p>Here the crucial step is at the third equality, which follows from
independence.</p>
<p>Independence means that if <span class="math notranslate nohighlight">\(i \not= j\)</span>, then the covariance term <span class="math notranslate nohighlight">\(\mathbb E (X_i - \mu)(X_j - \mu)\)</span> drops out.</p>
<p>As a result, <span class="math notranslate nohighlight">\(n^2 - n\)</span> terms vanish, leading us to a final expression that goes to zero in <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>Combining our last result with <a class="reference internal" href="#equation-lln-cheb">(11.3)</a>, we come to the estimate</p>
<div class="math notranslate nohighlight" id="equation-lln-cheb2">
<span class="eqno">(11.4)<a class="headerlink" href="#equation-lln-cheb2" title="Permalink to this equation">#</a></span>\[\mathbb P \left\{ | \bar X_n - \mu | \geq \epsilon \right\}
\leq \frac{\sigma^2}{n \epsilon^2}\]</div>
<p>The claim in <a class="reference internal" href="#equation-lln-ip">(11.2)</a> is now clear.</p>
<p>Of course, if the sequence <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> is correlated, then the cross-product terms
<span class="math notranslate nohighlight">\(\mathbb E (X_i - \mu)(X_j - \mu)\)</span> are not necessarily zero.</p>
<p>While this doesn’t mean that the same line of argument is impossible, it does mean
that if we want a similar result then the covariances should be “almost zero”
for “most” of these terms.</p>
<p>In a long sequence, this would be true if, for example, <span class="math notranslate nohighlight">\(\mathbb E (X_i - \mu)(X_j - \mu)\)</span>
approached zero when the difference between <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> became
large.</p>
<p>In other words, the LLN can still work if the sequence <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> has a kind of “asymptotic independence”, in the sense that correlation falls to zero as variables become further apart in the sequence.</p>
<p>This idea is very important in time series analysis, and we’ll come across it again soon enough.</p>
</section>
<section id="illustration">
<h3><span class="section-number">11.3.3. </span>Illustration<a class="headerlink" href="#illustration" title="Permalink to this heading">#</a></h3>
<p id="index-6">Let’s now illustrate the classical IID law of large numbers using simulation.</p>
<p>In particular, we aim to generate some sequences of IID random variables and plot the evolution
of <span class="math notranslate nohighlight">\(\bar X_n\)</span> as <span class="math notranslate nohighlight">\(n\)</span> increases.</p>
<p>Below is a figure that does just this (as usual, you can click on it to expand it).</p>
<p>It shows IID observations from three different distributions and plots <span class="math notranslate nohighlight">\(\bar X_n\)</span> against <span class="math notranslate nohighlight">\(n\)</span> in each case.</p>
<p>The dots represent the underlying observations <span class="math notranslate nohighlight">\(X_i\)</span> for <span class="math notranslate nohighlight">\(i = 1, \ldots, 100\)</span>.</p>
<p>In each of the three cases, convergence of <span class="math notranslate nohighlight">\(\bar X_n\)</span> to <span class="math notranslate nohighlight">\(\mu\)</span> occurs as predicted</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Arbitrary collection of distributions</span>
<span class="n">distributions</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;student&#39;s t with 10 degrees of freedom&quot;</span><span class="p">:</span> <span class="n">t</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
                 <span class="s2">&quot;β(2, 2)&quot;</span><span class="p">:</span> <span class="n">beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                 <span class="s2">&quot;lognormal LN(0, 1/2)&quot;</span><span class="p">:</span> <span class="n">lognorm</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
                 <span class="s2">&quot;γ(5, 1/2)&quot;</span><span class="p">:</span> <span class="n">gamma</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
                 <span class="s2">&quot;poisson(4)&quot;</span><span class="p">:</span> <span class="n">poisson</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span>
                 <span class="s2">&quot;exponential with λ = 1&quot;</span><span class="p">:</span> <span class="n">expon</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span>

<span class="c1"># Create a figure and some axes</span>
<span class="n">num_plots</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">num_plots</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>

<span class="c1"># Set some plotting parameters to improve layout</span>
<span class="n">bbox</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.02</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">.102</span><span class="p">)</span>
<span class="n">legend_args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ncol&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
               <span class="s1">&#39;bbox_to_anchor&#39;</span><span class="p">:</span> <span class="n">bbox</span><span class="p">,</span>
               <span class="s1">&#39;loc&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
               <span class="s1">&#39;mode&#39;</span><span class="p">:</span> <span class="s1">&#39;expand&#39;</span><span class="p">}</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
    <span class="c1"># Choose a randomly selected distribution</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">distributions</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
    <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="c1"># Generate n draws from the distribution</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="c1"># Compute sample mean at each n</span>
    <span class="n">sample_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
        <span class="n">sample_mean</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># Plot</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="n">data</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">axlabel</span> <span class="o">=</span> <span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">bar</span><span class="si">{X}</span><span class="s1">_n$ for $X_i \sim$&#39;</span> <span class="o">+</span> <span class="n">name</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="n">sample_mean</span><span class="p">,</span> <span class="s1">&#39;g-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">axlabel</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="p">[</span><span class="n">m</span><span class="p">]</span> <span class="o">*</span> <span class="n">n</span><span class="p">,</span> <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="n">m</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="o">**</span><span class="n">legend_args</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3da09891e9bfcf4024c2a7f5f2d92f4451929797aeb96f37c75264c80b1d9061.png" src="_images/3da09891e9bfcf4024c2a7f5f2d92f4451929797aeb96f37c75264c80b1d9061.png" />
</div>
</div>
<p>The three distributions are chosen at random from a selection stored in the dictionary <code class="docutils literal notranslate"><span class="pre">distributions</span></code>.</p>
</section>
</section>
<section id="clt">
<h2><a class="toc-backref" href="#id7"><span class="section-number">11.4. </span>CLT</a><a class="headerlink" href="#clt" title="Permalink to this heading">#</a></h2>
<p id="index-7">Next, we turn to the central limit theorem, which tells us about the distribution of the deviation between sample averages and population means.</p>
<section id="statement-of-the-theorem">
<h3><span class="section-number">11.4.1. </span>Statement of the Theorem<a class="headerlink" href="#statement-of-the-theorem" title="Permalink to this heading">#</a></h3>
<p>The central limit theorem is one of the most remarkable results in all of mathematics.</p>
<p>In the classical IID setting, it tells us the following:</p>
<p id="statement-clt">If the sequence <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> is IID, with common mean
<span class="math notranslate nohighlight">\(\mu\)</span> and common variance <span class="math notranslate nohighlight">\(\sigma^2 \in (0, \infty)\)</span>, then</p>
<div class="math notranslate nohighlight" id="equation-lln-clt">
<span class="eqno">(11.5)<a class="headerlink" href="#equation-lln-clt" title="Permalink to this equation">#</a></span>\[\sqrt{n} ( \bar X_n - \mu ) \stackrel { d } {\to} N(0, \sigma^2)
\quad \text{as} \quad
n \to \infty\]</div>
<p>Here <span class="math notranslate nohighlight">\(\stackrel { d } {\to} N(0, \sigma^2)\)</span> indicates <a class="reference external" href="https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_distribution">convergence in distribution</a> to a centered (i.e, zero mean) normal with standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
</section>
<section id="intuition">
<h3><span class="section-number">11.4.2. </span>Intuition<a class="headerlink" href="#intuition" title="Permalink to this heading">#</a></h3>
<p id="index-8">The striking implication of the CLT is that for <strong>any</strong> distribution with
finite second moment, the simple operation of adding independent
copies <strong>always</strong> leads to a Gaussian curve.</p>
<p>A relatively simple proof of the central limit theorem can be obtained by
working with characteristic functions (see, e.g., theorem 9.5.6 of <span id="id2">[<a class="reference internal" href="zreferences.html#id158" title="R M Dudley. Real Analysis and Probability. Cambridge Studies in Advanced Mathematics. Cambridge University Press, 2002.">Dud02</a>]</span>).</p>
<p>The proof is elegant but almost anticlimactic, and it provides surprisingly little intuition.</p>
<p>In fact, all of the proofs of the CLT that we know are similar in this respect.</p>
<p>Why does adding independent copies produce a bell-shaped distribution?</p>
<p>Part of the answer can be obtained by investigating the addition of independent Bernoulli
random variables.</p>
<p>In particular, let <span class="math notranslate nohighlight">\(X_i\)</span> be binary, with <span class="math notranslate nohighlight">\(\mathbb P\{X_i = 0\} = \mathbb P\{X_i =
1 \} = 0.5\)</span>, and let <span class="math notranslate nohighlight">\(X_1, \ldots, X_n\)</span> be independent.</p>
<p>Think of <span class="math notranslate nohighlight">\(X_i = 1\)</span> as a “success”, so that <span class="math notranslate nohighlight">\(Y_n = \sum_{i=1}^n X_i\)</span> is the number of successes in <span class="math notranslate nohighlight">\(n\)</span> trials.</p>
<p>The next figure plots the probability mass function of <span class="math notranslate nohighlight">\(Y_n\)</span> for <span class="math notranslate nohighlight">\(n = 1, 2, 4, 8\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">ns</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]</span>
<span class="n">dom</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">ns</span><span class="p">):</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">binom</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">dom</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">dom</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">),</span>
           <span class="n">xticks</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)),</span> <span class="n">yticks</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>
           <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">$&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3cb11d584aeb757e737d6d17aa4ac8e479f249b4e5e54ea8dfba8ddbbf7ae549.png" src="_images/3cb11d584aeb757e737d6d17aa4ac8e479f249b4e5e54ea8dfba8ddbbf7ae549.png" />
</div>
</div>
<p>When <span class="math notranslate nohighlight">\(n = 1\)</span>, the distribution is flat — one success or no successes
have the same probability.</p>
<p>When <span class="math notranslate nohighlight">\(n = 2\)</span> we can either have 0, 1 or 2 successes.</p>
<p>Notice the peak in probability mass at the mid-point <span class="math notranslate nohighlight">\(k=1\)</span>.</p>
<p>The reason is that there are more ways to get 1 success (“fail then succeed”
or “succeed then fail”) than to get zero or two successes.</p>
<p>Moreover, the two trials are independent, so the outcomes “fail then succeed” and “succeed then
fail” are just as likely as the outcomes “fail then fail” and “succeed then succeed”.</p>
<p>(If there was positive correlation, say, then “succeed then fail” would be less likely than “succeed then succeed”)</p>
<p>Here, already we have the essence of the CLT: addition under independence leads probability mass to pile up in the middle and thin out at the tails.</p>
<p>For <span class="math notranslate nohighlight">\(n = 4\)</span> and <span class="math notranslate nohighlight">\(n = 8\)</span> we again get a peak at the “middle” value (halfway between the minimum and the maximum possible value).</p>
<p>The intuition is the same — there are simply more ways to get these middle outcomes.</p>
<p>If we continue, the bell-shaped curve becomes even more pronounced.</p>
<p>We are witnessing the <a class="reference external" href="https://en.wikipedia.org/wiki/De_Moivre%E2%80%93Laplace_theorem">binomial approximation of the normal distribution</a>.</p>
</section>
<section id="simulation-1">
<h3><span class="section-number">11.4.3. </span>Simulation 1<a class="headerlink" href="#simulation-1" title="Permalink to this heading">#</a></h3>
<p>Since the CLT seems almost magical, running simulations that verify its implications is one good way to build intuition.</p>
<p>To this end, we now perform the following simulation</p>
<ol class="arabic simple">
<li><p>Choose an arbitrary distribution <span class="math notranslate nohighlight">\(F\)</span> for the underlying observations <span class="math notranslate nohighlight">\(X_i\)</span>.</p></li>
<li><p>Generate independent draws of <span class="math notranslate nohighlight">\(Y_n := \sqrt{n} ( \bar X_n - \mu )\)</span>.</p></li>
<li><p>Use these draws to compute some measure of their distribution — such as a histogram.</p></li>
<li><p>Compare the latter to <span class="math notranslate nohighlight">\(N(0, \sigma^2)\)</span>.</p></li>
</ol>
<p>Here’s some code that does exactly this for the exponential distribution
<span class="math notranslate nohighlight">\(F(x) = 1 - e^{- \lambda x}\)</span>.</p>
<p>(Please experiment with other choices of <span class="math notranslate nohighlight">\(F\)</span>, but remember that, to conform with the conditions of the CLT, the distribution must have a finite second moment.)</p>
<div class="cell docutils container" id="sim-one">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">250</span>                  <span class="c1"># Choice of n</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">100000</span>               <span class="c1"># Number of draws of Y_n</span>
<span class="n">distribution</span> <span class="o">=</span> <span class="n">expon</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Exponential distribution, λ = 1/2</span>
<span class="n">μ</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">distribution</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="c1"># Draw underlying RVs. Each row contains a draw of X_1,..,X_n</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="c1"># Compute mean of each row, producing k draws of \bar X_n</span>
<span class="n">sample_means</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Generate observations of Y_n</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">sample_means</span> <span class="o">-</span> <span class="n">μ</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span> <span class="o">*</span> <span class="n">s</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">s</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">xgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">s</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$N(0, \sigma^2)$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/230f5ffcfa8482a9b4977b113002a6abe0102993cc24306c10d90733dda4e84c.png" src="_images/230f5ffcfa8482a9b4977b113002a6abe0102993cc24306c10d90733dda4e84c.png" />
</div>
</div>
<p>Notice the absence of for loops — every operation is vectorized, meaning that the major calculations are all shifted to highly optimized C code.</p>
<p>The fit to the normal density is already tight and can be further improved by increasing <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
<p>You can also experiment with other specifications of <span class="math notranslate nohighlight">\(F\)</span>.</p>
</section>
<section id="simulation-2">
<h3><span class="section-number">11.4.4. </span>Simulation 2<a class="headerlink" href="#simulation-2" title="Permalink to this heading">#</a></h3>
<p>Our next simulation is somewhat like the first, except that we aim to track the distribution of <span class="math notranslate nohighlight">\(Y_n := \sqrt{n} ( \bar X_n - \mu )\)</span> as <span class="math notranslate nohighlight">\(n\)</span> increases.</p>
<p>In the simulation, we’ll be working with random variables having <span class="math notranslate nohighlight">\(\mu = 0\)</span>.</p>
<p>Thus, when <span class="math notranslate nohighlight">\(n=1\)</span>, we have <span class="math notranslate nohighlight">\(Y_1 = X_1\)</span>, so the first distribution is just
the distribution of the underlying random variable.</p>
<p>For <span class="math notranslate nohighlight">\(n=2\)</span>, the distribution of <span class="math notranslate nohighlight">\(Y_2\)</span> is that of <span class="math notranslate nohighlight">\((X_1 + X_2) / \sqrt{2}\)</span>, and so on.</p>
<p>What we expect is that, regardless of the distribution of the underlying
random variable, the distribution of <span class="math notranslate nohighlight">\(Y_n\)</span> will smooth out into a bell-shaped curve.</p>
<p>The next figure shows this process for <span class="math notranslate nohighlight">\(X_i \sim f\)</span>, where <span class="math notranslate nohighlight">\(f\)</span> was
specified as the convex combination of three different beta densities.</p>
<p>(Taking a convex combination is an easy way to produce an irregular shape for <span class="math notranslate nohighlight">\(f\)</span>.)</p>
<p>In the figure, the closest density is that of <span class="math notranslate nohighlight">\(Y_1\)</span>, while the furthest is that of
<span class="math notranslate nohighlight">\(Y_5\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">beta_dist</span> <span class="o">=</span> <span class="n">beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">gen_x_draws</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a flat array containing k independent draws from the</span>
<span class="sd">    distribution of X, the underlying random variable.  This distribution</span>
<span class="sd">    is itself a convex combination of three beta distributions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bdraws</span> <span class="o">=</span> <span class="n">beta_dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
    <span class="c1"># Transform rows, so each represents a different distribution</span>
    <span class="n">bdraws</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="mf">0.5</span>
    <span class="n">bdraws</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+=</span> <span class="mf">0.6</span>
    <span class="n">bdraws</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-=</span> <span class="mf">1.1</span>
    <span class="c1"># Set X[i] = bdraws[j, i], where j is a random draw from {0, 1, 2}</span>
    <span class="n">js</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">bdraws</span><span class="p">[</span><span class="n">js</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="p">)]</span>
    <span class="c1"># Rescale, so that the random variable is zero mean</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span>

<span class="n">nmax</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">reps</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">ns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nmax</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Form a matrix Z such that each column is reps independent draws of X</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">reps</span><span class="p">,</span> <span class="n">nmax</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nmax</span><span class="p">):</span>
    <span class="n">Z</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">gen_x_draws</span><span class="p">(</span><span class="n">reps</span><span class="p">)</span>
<span class="c1"># Take cumulative sum across columns</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">Z</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Multiply j-th column by sqrt j</span>
<span class="n">Y</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">ns</span><span class="p">))</span> <span class="o">*</span> <span class="n">S</span>

<span class="c1"># Plot</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>

<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span>
<span class="n">gs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">gs</span><span class="p">)</span>

<span class="c1"># Build verts</span>
<span class="n">greys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">nmax</span><span class="p">)</span>
<span class="n">verts</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">ns</span><span class="p">:</span>
    <span class="n">density</span> <span class="o">=</span> <span class="n">gaussian_kde</span><span class="p">(</span><span class="n">Y</span><span class="p">[:,</span> <span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">density</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
    <span class="n">verts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)))</span>

<span class="n">poly</span> <span class="o">=</span> <span class="n">PolyCollection</span><span class="p">(</span><span class="n">verts</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">greys</span><span class="p">])</span>
<span class="n">poly</span><span class="o">.</span><span class="n">set_alpha</span><span class="p">(</span><span class="mf">0.85</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">add_collection3d</span><span class="p">(</span><span class="n">poly</span><span class="p">,</span> <span class="n">zs</span><span class="o">=</span><span class="n">ns</span><span class="p">,</span> <span class="n">zdir</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim3d</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nmax</span><span class="p">),</span> <span class="n">xticks</span><span class="o">=</span><span class="p">(</span><span class="n">ns</span><span class="p">),</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;$Y_n$&#39;</span><span class="p">,</span> <span class="n">zlabel</span><span class="o">=</span><span class="s1">&#39;$p(y_n)$&#39;</span><span class="p">,</span>
       <span class="n">xlabel</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">),</span> <span class="n">yticks</span><span class="o">=</span><span class="p">((</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="n">ylim3d</span><span class="o">=</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span>
       <span class="n">zlim3d</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span> <span class="n">zticks</span><span class="o">=</span><span class="p">((</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">)))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">invert_xaxis</span><span class="p">()</span>
<span class="c1"># Rotates the plot 30 deg on z axis and 45 deg on x axis</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">45</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b68bd55807ce301dee80c30d529f6948b2d30918abdee0271410604f5a23c8d2.png" src="_images/b68bd55807ce301dee80c30d529f6948b2d30918abdee0271410604f5a23c8d2.png" />
</div>
</div>
<p>As expected, the distribution smooths out into a bell curve as <span class="math notranslate nohighlight">\(n\)</span>
increases.</p>
<p>We leave you to investigate its contents if you wish to know more.</p>
<p>If you run the file from the ordinary IPython shell, the figure should pop up in a
window that you can rotate with your mouse, giving different views on the
density sequence.</p>
</section>
<section id="the-multivariate-case">
<span id="multivariate-clt"></span><h3><span class="section-number">11.4.5. </span>The Multivariate Case<a class="headerlink" href="#the-multivariate-case" title="Permalink to this heading">#</a></h3>
<span class="target" id="index-9"></span><p id="index-10">The law of large numbers and central limit theorem work just as nicely in multidimensional settings.</p>
<p>To state the results, let’s recall some elementary facts about random vectors.</p>
<p>A random vector <span class="math notranslate nohighlight">\(\mathbf X\)</span> is just a sequence of <span class="math notranslate nohighlight">\(k\)</span> random variables <span class="math notranslate nohighlight">\((X_1, \ldots, X_k)\)</span>.</p>
<p>Each realization of <span class="math notranslate nohighlight">\(\mathbf X\)</span> is an element of <span class="math notranslate nohighlight">\(\mathbb R^k\)</span>.</p>
<p>A collection of random vectors <span class="math notranslate nohighlight">\(\mathbf X_1, \ldots, \mathbf X_n\)</span> is called independent if, given any <span class="math notranslate nohighlight">\(n\)</span> vectors <span class="math notranslate nohighlight">\(\mathbf x_1, \ldots, \mathbf x_n\)</span> in <span class="math notranslate nohighlight">\(\mathbb R^k\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
\mathbb P\{\mathbf X_1 \leq \mathbf x_1,\ldots, \mathbf X_n \leq \mathbf x_n \}
= \mathbb P\{\mathbf X_1 \leq \mathbf x_1 \}
\times \cdots \times \mathbb P\{ \mathbf X_n \leq \mathbf x_n \}
\]</div>
<p>(The vector inequality <span class="math notranslate nohighlight">\(\mathbf X \leq \mathbf x\)</span> means that <span class="math notranslate nohighlight">\(X_j \leq x_j\)</span> for <span class="math notranslate nohighlight">\(j = 1,\ldots,k\)</span>)</p>
<p>Let <span class="math notranslate nohighlight">\(\mu_j := \mathbb E [X_j]\)</span> for all <span class="math notranslate nohighlight">\(j =1,\ldots,k\)</span>.</p>
<p>The expectation <span class="math notranslate nohighlight">\(\mathbb E [\mathbf X]\)</span> of <span class="math notranslate nohighlight">\(\mathbf X\)</span> is defined to be the vector of expectations:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbb E [\mathbf X] :=
\left(
\begin{array}{c}
    \mathbb E [X_1] \\
    \mathbb E [X_2] \\
    \vdots \\
    \mathbb E [X_k]
\end{array}
\right) =
\left(
\begin{array}{c}
    \mu_1 \\
    \mu_2\\
    \vdots \\
    \mu_k
\end{array}
\right) =: \boldsymbol \mu
\end{split}\]</div>
<p>The <em>variance-covariance matrix</em> of random vector <span class="math notranslate nohighlight">\(\mathbf X\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
\mathop{\mathrm{Var}}[\mathbf X]
:= \mathbb E
[ (\mathbf X - \boldsymbol \mu) (\mathbf X - \boldsymbol \mu)']
\]</div>
<p>Expanding this out, we get</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathop{\mathrm{Var}}[\mathbf X] =
\left(
\begin{array}{ccc}
    \mathbb E [(X_1 - \mu_1)(X_1 - \mu_1)]
        &amp; \cdots &amp; \mathbb E [(X_1 - \mu_1)(X_k - \mu_k)] \\
    \mathbb E [(X_2 - \mu_2)(X_1 - \mu_1)]
        &amp; \cdots &amp; \mathbb E [(X_2 - \mu_2)(X_k - \mu_k)] \\
    \vdots &amp; \vdots &amp; \vdots \\
    \mathbb E [(X_k - \mu_k)(X_1 - \mu_1)]
        &amp; \cdots &amp; \mathbb E [(X_k - \mu_k)(X_k - \mu_k)] \\
\end{array}
\right)
\end{split}\]</div>
<p>The <span class="math notranslate nohighlight">\(j,k\)</span>-th term is the scalar covariance between <span class="math notranslate nohighlight">\(X_j\)</span> and
<span class="math notranslate nohighlight">\(X_k\)</span>.</p>
<p>With this notation, we can proceed to the multivariate LLN and CLT.</p>
<p>Let <span class="math notranslate nohighlight">\(\mathbf X_1, \ldots, \mathbf X_n\)</span> be a sequence of independent and
identically distributed random vectors, each one taking values in
<span class="math notranslate nohighlight">\(\mathbb R^k\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(\boldsymbol \mu\)</span> be the vector <span class="math notranslate nohighlight">\(\mathbb E [\mathbf X_i]\)</span>, and let <span class="math notranslate nohighlight">\(\Sigma\)</span>
be the variance-covariance matrix of <span class="math notranslate nohighlight">\(\mathbf X_i\)</span>.</p>
<p>Interpreting vector addition and scalar multiplication in the usual way (i.e., pointwise), let</p>
<div class="math notranslate nohighlight">
\[
\bar{\mathbf X}_n := \frac{1}{n} \sum_{i=1}^n \mathbf X_i
\]</div>
<p>In this setting, the LLN tells us that</p>
<div class="math notranslate nohighlight" id="equation-lln-asmv">
<span class="eqno">(11.6)<a class="headerlink" href="#equation-lln-asmv" title="Permalink to this equation">#</a></span>\[\mathbb P \left\{ \bar{\mathbf X}_n \to \boldsymbol \mu \text{ as } n \to \infty \right\} = 1\]</div>
<p>Here <span class="math notranslate nohighlight">\(\bar{\mathbf X}_n \to \boldsymbol \mu\)</span> means that <span class="math notranslate nohighlight">\(\| \bar{\mathbf X}_n - \boldsymbol \mu \| \to 0\)</span>, where <span class="math notranslate nohighlight">\(\| \cdot \|\)</span> is the standard Euclidean norm.</p>
<p>The CLT tells us that, provided <span class="math notranslate nohighlight">\(\Sigma\)</span> is finite,</p>
<div class="math notranslate nohighlight" id="equation-lln-cltmv">
<span class="eqno">(11.7)<a class="headerlink" href="#equation-lln-cltmv" title="Permalink to this equation">#</a></span>\[\sqrt{n} ( \bar{\mathbf X}_n - \boldsymbol \mu ) \stackrel { d } {\to} N(\mathbf 0, \Sigma)
\quad \text{as} \quad
n \to \infty\]</div>
</section>
</section>
<section id="exercises">
<h2><a class="toc-backref" href="#id8"><span class="section-number">11.5. </span>Exercises</a><a class="headerlink" href="#exercises" title="Permalink to this heading">#</a></h2>
<div class="exercise admonition" id="lln_ex1">

<p class="admonition-title"><span class="caption-number">Exercise 11.1 </span></p>
<section id="exercise-content">
<p>One very useful consequence of the central limit theorem is as follows.</p>
<p>Assume the conditions of the CLT as <a class="reference internal" href="#statement-clt"><span class="std std-ref">stated above</span></a>.</p>
<p>If <span class="math notranslate nohighlight">\(g \colon \mathbb R \to \mathbb R\)</span> is differentiable at <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(g'(\mu) \not= 0\)</span>, then</p>
<div class="math notranslate nohighlight" id="equation-lln-dm">
<span class="eqno">(11.8)<a class="headerlink" href="#equation-lln-dm" title="Permalink to this equation">#</a></span>\[\sqrt{n} \{ g(\bar X_n) - g(\mu) \}
\stackrel { d } {\to} N(0, g'(\mu)^2 \sigma^2)
\quad \text{as} \quad
n \to \infty\]</div>
<p>This theorem is used frequently in statistics to obtain the asymptotic distribution of estimators — many of which can be expressed as functions of sample means.</p>
<p>(These kinds of results are often said to use the “delta method”.)</p>
<p>The proof is based on a Taylor expansion of <span class="math notranslate nohighlight">\(g\)</span> around the point <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
<p>Taking the result as given, let the distribution <span class="math notranslate nohighlight">\(F\)</span> of each <span class="math notranslate nohighlight">\(X_i\)</span> be uniform on <span class="math notranslate nohighlight">\([0, \pi / 2]\)</span> and let <span class="math notranslate nohighlight">\(g(x) = \sin(x)\)</span>.</p>
<p>Derive the asymptotic distribution of <span class="math notranslate nohighlight">\(\sqrt{n} \{ g(\bar X_n) - g(\mu) \}\)</span> and illustrate convergence in the same spirit as the program discussed <a class="reference internal" href="#sim-one"><span class="std std-ref">above</span></a>.</p>
<p>What happens when you replace <span class="math notranslate nohighlight">\([0, \pi / 2]\)</span> with <span class="math notranslate nohighlight">\([0, \pi]\)</span>?</p>
<p>What is the source of the problem?</p>
</section>
</div>
<div class="solution dropdown admonition" id="lln_clt-solution-1">

<p class="admonition-title">Solution to<a class="reference internal" href="#lln_ex1"> Exercise 11.1</a></p>
<section id="solution-content">
<p>Here is one solution</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Illustrates the delta method, a consequence of the central limit theorem.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Set parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">replications</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">distribution</span> <span class="o">=</span> <span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">μ</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">distribution</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span>
<span class="n">g_prime</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span>

<span class="c1"># Generate obs of sqrt{n} (g(X_n) - g(μ))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="n">replications</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="n">sample_means</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Compute mean of each row</span>
<span class="n">error_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">g</span><span class="p">(</span><span class="n">sample_means</span><span class="p">)</span> <span class="o">-</span> <span class="n">g</span><span class="p">(</span><span class="n">μ</span><span class="p">))</span>

<span class="c1"># Plot</span>
<span class="n">asymptotic_sd</span> <span class="o">=</span> <span class="n">g_prime</span><span class="p">(</span><span class="n">μ</span><span class="p">)</span> <span class="o">*</span> <span class="n">s</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">xmin</span> <span class="o">=</span> <span class="o">-</span><span class="mi">3</span> <span class="o">*</span> <span class="n">g_prime</span><span class="p">(</span><span class="n">μ</span><span class="p">)</span> <span class="o">*</span> <span class="n">s</span>
<span class="n">xmax</span> <span class="o">=</span> <span class="o">-</span><span class="n">xmin</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">error_obs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">xgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">lb</span> <span class="o">=</span> <span class="s2">&quot;$N(0, g&#39;(\mu)^2  \sigma^2)$&quot;</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">asymptotic_sd</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lb</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ab87dac111f4e77aaebcd05b65e58a8bd274f2afe0ed61f6ef06258fc89e0ab0.png" src="_images/ab87dac111f4e77aaebcd05b65e58a8bd274f2afe0ed61f6ef06258fc89e0ab0.png" />
</div>
</div>
<p>What happens when you replace <span class="math notranslate nohighlight">\([0, \pi / 2]\)</span> with
<span class="math notranslate nohighlight">\([0, \pi]\)</span>?</p>
<p>In this case, the mean <span class="math notranslate nohighlight">\(\mu\)</span> of this distribution is
<span class="math notranslate nohighlight">\(\pi/2\)</span>, and since <span class="math notranslate nohighlight">\(g' = \cos\)</span>, we have <span class="math notranslate nohighlight">\(g'(\mu) = 0\)</span>.</p>
<p>Hence the conditions of the delta theorem are not satisfied.</p>
</section>
</div>
<div class="exercise admonition" id="lln_ex2">

<p class="admonition-title"><span class="caption-number">Exercise 11.2 </span></p>
<section id="exercise-content">
<p>Here’s a result that’s often used in developing statistical tests, and is connected to the multivariate central limit theorem.</p>
<p>If you study econometric theory, you will see this result used again and again.</p>
<p>Assume the setting of the multivariate CLT <a class="reference internal" href="#multivariate-clt"><span class="std std-ref">discussed above</span></a>, so that</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf X_1, \ldots, \mathbf X_n\)</span> is a sequence of IID random vectors, each taking values in <span class="math notranslate nohighlight">\(\mathbb R^k\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol \mu := \mathbb E [\mathbf X_i]\)</span>, and <span class="math notranslate nohighlight">\(\Sigma\)</span> is the variance-covariance matrix of <span class="math notranslate nohighlight">\(\mathbf X_i\)</span>.</p></li>
<li><p>The convergence</p></li>
</ol>
<div class="math notranslate nohighlight" id="equation-lln-cltmv2">
<span class="eqno">(11.9)<a class="headerlink" href="#equation-lln-cltmv2" title="Permalink to this equation">#</a></span>\[\sqrt{n} ( \bar{\mathbf X}_n - \boldsymbol \mu ) \stackrel { d } {\to} N(\mathbf 0, \Sigma)\]</div>
<p>is valid.</p>
<p>In a statistical setting, one often wants the right-hand side to be <strong>standard</strong> normal so that confidence intervals are easily computed.</p>
<p>This normalization can be achieved on the basis of three observations.</p>
<p>First, if <span class="math notranslate nohighlight">\(\mathbf X\)</span> is a random vector in <span class="math notranslate nohighlight">\(\mathbb R^k\)</span> and <span class="math notranslate nohighlight">\(\mathbf A\)</span> is constant and <span class="math notranslate nohighlight">\(k \times k\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
\mathop{\mathrm{Var}}[\mathbf A \mathbf X]
= \mathbf A \mathop{\mathrm{Var}}[\mathbf X] \mathbf A'
\]</div>
<p>Second, by the <a class="reference external" href="https://en.wikipedia.org/wiki/Continuous_mapping_theorem">continuous mapping theorem</a>, if <span class="math notranslate nohighlight">\(\mathbf Z_n \stackrel{d}{\to} \mathbf Z\)</span> in <span class="math notranslate nohighlight">\(\mathbb R^k\)</span> and <span class="math notranslate nohighlight">\(\mathbf A\)</span> is constant and <span class="math notranslate nohighlight">\(k \times k\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
\mathbf A \mathbf Z_n
\stackrel{d}{\to} \mathbf A \mathbf Z
\]</div>
<p>Third, if <span class="math notranslate nohighlight">\(\mathbf S\)</span> is a <span class="math notranslate nohighlight">\(k \times k\)</span> symmetric positive definite matrix, then there
exists a symmetric positive definite matrix <span class="math notranslate nohighlight">\(\mathbf Q\)</span>, called the inverse
<a class="reference external" href="https://en.wikipedia.org/wiki/Square_root_of_a_matrix">square root</a> of <span class="math notranslate nohighlight">\(\mathbf S\)</span>, such that</p>
<div class="math notranslate nohighlight">
\[
\mathbf Q \mathbf S\mathbf Q' = \mathbf I
\]</div>
<p>Here <span class="math notranslate nohighlight">\(\mathbf I\)</span> is the <span class="math notranslate nohighlight">\(k \times k\)</span> identity matrix.</p>
<p>Putting these things together, your first exercise is to show that if
<span class="math notranslate nohighlight">\(\mathbf Q\)</span> is the inverse square root of <span class="math notranslate nohighlight">\(\mathbf \Sigma\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
\mathbf Z_n := \sqrt{n} \mathbf Q ( \bar{\mathbf X}_n - \boldsymbol \mu )
\stackrel{d}{\to}
\mathbf Z \sim N(\mathbf 0, \mathbf I)
\]</div>
<p>Applying the continuous mapping theorem one more time tells us that</p>
<div class="math notranslate nohighlight">
\[
\| \mathbf Z_n \|^2
\stackrel{d}{\to}
\| \mathbf Z \|^2
\]</div>
<p>Given the distribution of <span class="math notranslate nohighlight">\(\mathbf Z\)</span>, we conclude that</p>
<div class="math notranslate nohighlight" id="equation-lln-ctc">
<span class="eqno">(11.10)<a class="headerlink" href="#equation-lln-ctc" title="Permalink to this equation">#</a></span>\[n \| \mathbf Q ( \bar{\mathbf X}_n - \boldsymbol \mu ) \|^2
\stackrel{d}{\to}
\chi^2(k)\]</div>
<p>where <span class="math notranslate nohighlight">\(\chi^2(k)\)</span> is the chi-squared distribution with <span class="math notranslate nohighlight">\(k\)</span> degrees
of freedom.</p>
<p>(Recall that <span class="math notranslate nohighlight">\(k\)</span> is the dimension of <span class="math notranslate nohighlight">\(\mathbf X_i\)</span>, the underlying random vectors.)</p>
<p>Your second exercise is to illustrate the convergence in <a class="reference internal" href="#equation-lln-ctc">(11.10)</a> with a simulation.</p>
<p>In doing so, let</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf X_i :=
\left(
\begin{array}{c}
    W_i \\
    U_i + W_i
\end{array}
\right)
\end{split}\]</div>
<p>where</p>
<ul class="simple">
<li><p>each <span class="math notranslate nohighlight">\(W_i\)</span> is an IID draw from the uniform distribution on <span class="math notranslate nohighlight">\([-1, 1]\)</span>.</p></li>
<li><p>each <span class="math notranslate nohighlight">\(U_i\)</span> is an IID draw from the uniform distribution on <span class="math notranslate nohighlight">\([-2, 2]\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(U_i\)</span> and <span class="math notranslate nohighlight">\(W_i\)</span> are independent of each other.</p></li>
</ul>
<div class="dropdown admonition hint">
<p class="admonition-title">Hint</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">scipy.linalg.sqrtm(A)</span></code> computes the square root of <code class="docutils literal notranslate"><span class="pre">A</span></code>.  You still need to invert it.</p></li>
<li><p>You should be able to work out <span class="math notranslate nohighlight">\(\Sigma\)</span> from the preceding information.</p></li>
</ol>
</div>
</section>
</div>
<div class="solution dropdown admonition" id="lln_clt-solution-3">

<p class="admonition-title">Solution to<a class="reference internal" href="#lln_ex2"> Exercise 11.2</a></p>
<section id="solution-content">
<p>First we want to verify the claim that</p>
<div class="math notranslate nohighlight">
\[
\sqrt{n} \mathbf Q ( \bar{\mathbf X}_n - \boldsymbol \mu )
\stackrel{d}{\to}
N(\mathbf 0, \mathbf I)
\]</div>
<p>This is straightforward given the facts presented in the exercise.</p>
<p>Let</p>
<div class="math notranslate nohighlight">
\[
\mathbf Y_n := \sqrt{n} ( \bar{\mathbf X}_n - \boldsymbol \mu )
\quad \text{and} \quad
\mathbf Y \sim N(\mathbf 0, \Sigma)
\]</div>
<p>By the multivariate CLT and the continuous mapping theorem, we have</p>
<div class="math notranslate nohighlight">
\[
\mathbf Q \mathbf Y_n
\stackrel{d}{\to}
\mathbf Q \mathbf Y
\]</div>
<p>Since linear combinations of normal random variables are normal, the
vector <span class="math notranslate nohighlight">\(\mathbf Q \mathbf Y\)</span> is also normal.</p>
<p>Its mean is clearly <span class="math notranslate nohighlight">\(\mathbf 0\)</span>, and its variance-covariance
matrix is</p>
<div class="math notranslate nohighlight">
\[
\mathrm{Var}[\mathbf Q \mathbf Y]
= \mathbf Q \mathrm{Var}[\mathbf Y] \mathbf Q'
= \mathbf Q \Sigma \mathbf Q'
= \mathbf I
\]</div>
<p>In conclusion,
<span class="math notranslate nohighlight">\(\mathbf Q \mathbf Y_n \stackrel{d}{\to} \mathbf Q \mathbf Y \sim N(\mathbf 0, \mathbf I)\)</span>,
which is what we aimed to show.</p>
<p>Now we turn to the simulation exercise.</p>
<p>Our solution is as follows</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">250</span>
<span class="n">replications</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">dw</span> <span class="o">=</span> <span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Uniform(-1, 1)</span>
<span class="n">du</span> <span class="o">=</span> <span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># Uniform(-2, 2)</span>
<span class="n">sw</span><span class="p">,</span> <span class="n">su</span> <span class="o">=</span> <span class="n">dw</span><span class="o">.</span><span class="n">std</span><span class="p">(),</span> <span class="n">du</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">vw</span><span class="p">,</span> <span class="n">vu</span> <span class="o">=</span> <span class="n">sw</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">su</span><span class="o">**</span><span class="mi">2</span>
<span class="n">Σ</span> <span class="o">=</span> <span class="p">((</span><span class="n">vw</span><span class="p">,</span> <span class="n">vw</span><span class="p">),</span> <span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">vw</span> <span class="o">+</span> <span class="n">vu</span><span class="p">))</span>
<span class="n">Σ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Σ</span><span class="p">)</span>

<span class="c1"># Compute Σ^{-1/2}</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">sqrtm</span><span class="p">(</span><span class="n">Σ</span><span class="p">))</span>

<span class="c1"># Generate observations of the normalized sample mean</span>
<span class="n">error_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">replications</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">replications</span><span class="p">):</span>
    <span class="c1"># Generate one sequence of bivariate shocks</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">dw</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">du</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="c1"># Construct the n observations of the random vector</span>
    <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">W</span>
    <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">W</span> <span class="o">+</span> <span class="n">U</span>
    <span class="c1"># Construct the i-th observation of Y_n</span>
    <span class="n">error_obs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Premultiply by Q and then take the squared norm</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">Q</span> <span class="o">@</span> <span class="n">error_obs</span>
<span class="n">chisq_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">temp</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">xmax</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">xgrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">lb</span> <span class="o">=</span> <span class="s2">&quot;Chi-squared with 2 degrees of freedom&quot;</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">chi2</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lb</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">chisq_obs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/414ecf64a874538b15691139d86691f31d249619f708f92ef5934a255236954d.png" src="_images/414ecf64a874538b15691139d86691f31d249619f708f92ef5934a255236954d.png" />
</div>
</div>
</section>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tools and Techniques
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="geom_series.html">
   1. Geometric Series for Elementary Economics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="sir_model.html">
   2. Modeling COVID 19
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_algebra.html">
   3. Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="qr_decomp.html">
   4. QR Decomposition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="complex_and_trig.html">
   5. Complex Numbers and Trigonometry
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="eig_circulant.html">
   6. Circulant Matrices
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="svd_intro.html">
   7. Singular Value Decomposition (SVD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="var_dmd.html">
   8. VARs and DMDs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="newton_method.html">
   9. Using Newton’s Method to Solve Economic Models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Elementary Statistics
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="prob_matrix.html">
   10. Elementary Probability with Matrices
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   11. LLN and CLT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="prob_meaning.html">
   12. Two Meanings of Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multi_hyper.html">
   13. Multivariate Hypergeometric Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multivariate_normal.html">
   14. Multivariate Normal Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="heavy_tails.html">
   15. Heavy-Tailed Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hoist_failure.html">
   16. Fault Tree Uncertainties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="back_prop.html">
   17. Introduction to Artificial Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rand_resp.html">
   18. Randomized Response Surveys
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="util_rand_resp.html">
   19. Expected Utilities of Random Responses
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear Programming
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lp_intro.html">
   20. Linear Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="opt_transport.html">
   21. Optimal Transport
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="von_neumann_model.html">
   22. Von Neumann Growth Model (and a Generalization)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Dynamics
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="scalar_dynam.html">
   23. Dynamics in One Dimension
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ar1_processes.html">
   24. AR1 Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="finite_markov.html">
   25. Finite Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="inventory_dynamics.html">
   26. Inventory Dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models.html">
   27. Linear State Space Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="samuelson.html">
   28. Samuelson Multiplier-Accelerator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kesten_processes.html">
   29. Kesten Processes and Firm Dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wealth_dynamics.html">
   30. Wealth Distribution Dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kalman.html">
   31. A First Look at the Kalman Filter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kalman_2.html">
   32. Another Look at the Kalman Filter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="short_path.html">
   33. Shortest Paths
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Search
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_model.html">
   34. Job Search I: The McCall Search Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_model_with_separation.html">
   35. Job Search II: Search and Separation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_fitted_vfi.html">
   36. Job Search III: Fitted Value Function Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_correlated.html">
   37. Job Search IV: Correlated Wage Offers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="career.html">
   38. Job Search V: Modeling Career Choice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="jv.html">
   39. Job Search VI: On-the-Job Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_q.html">
   40. Job Search VII: A McCall Worker Q-Learns
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Consumption, Savings and Capital
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="cass_koopmans_1.html">
   41. Cass-Koopmans Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cass_koopmans_2.html">
   42. Cass-Koopmans Competitive Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cake_eating_problem.html">
   43. Cake Eating I: Introduction to Optimal Saving
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cake_eating_numerical.html">
   44. Cake Eating II: Numerical Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optgrowth.html">
   45. Optimal Growth I: The Stochastic Optimal Growth Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optgrowth_fast.html">
   46. Optimal Growth II: Accelerating the Code with Numba
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coleman_policy_iter.html">
   47. Optimal Growth III: Time Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="egm_policy_iter.html">
   48. Optimal Growth IV: The Endogenous Grid Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ifp.html">
   49. The Income Fluctuation Problem I: Basic Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ifp_advanced.html">
   50. The Income Fluctuation Problem II: Stochastic Returns on Assets
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bayes Law
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="bayes_nonconj.html">
   51. Non-Conjugate Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ar1_bayes.html">
   52. Posterior Distributions for  AR(1) Parameters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ar1_turningpts.html">
   53. Forecasting  an AR(1) Process
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Information
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="odu.html">
   54. Job Search VII: Search with Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="likelihood_ratio_process.html">
   55. Likelihood Ratio Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="imp_sample.html">
   56. Computing Mean of a Likelihood Ratio Process
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wald_friedman.html">
   57. A Problem that Stumped Milton Friedman
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="exchangeable.html">
   58. Exchangeability and Bayesian Updating
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="likelihood_bayes.html">
   59. Likelihood Ratio Processes and Bayesian Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mix_model.html">
   60. Incorrect Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="navy_captain.html">
   61. Bayesian versus Frequentist Decision Rules
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  LQ Control
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lqcontrol.html">
   62. LQ Control: Foundations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lagrangian_lqdp.html">
   63. Lagrangian for LQ Control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cross_product_trick.html">
   64. Eliminating Cross Products
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="perm_income.html">
   65. The Permanent Income Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="perm_income_cons.html">
   66. Permanent Income II: LQ Techniques
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lq_inventories.html">
   67. Production Smoothing via Inventories
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Multiple Agent Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="schelling.html">
   68. Schelling’s Segregation Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lake_model.html">
   69. A Lake Model of Employment and Unemployment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rational_expectations.html">
   70. Rational Expectations Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="re_with_feedback.html">
   71. Stability in Linear Rational Expectations Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markov_perf.html">
   72. Markov Perfect Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="uncertainty_traps.html">
   73. Uncertainty Traps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="aiyagari.html">
   74. The Aiyagari Model
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Asset Pricing and Finance
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="markov_asset.html">
   75. Asset Pricing: Finite State Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ge_arrow.html">
   76. Competitive Equilibria with Arrow Securities
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="harrison_kreps.html">
   77. Heterogeneous Beliefs and Bubbles
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data and Empirics
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="pandas_panel.html">
   78. Pandas for Panel Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ols.html">
   79. Linear Regression in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mle.html">
   80. Maximum Likelihood Estimation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Auctions
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="two_auctions.html">
   81. First-Price and Second-Price Auctions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="house_auction.html">
   82. Multiple Good Allocation Mechanisms
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   83. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   84. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="status.html">
   85. Execution Statistics
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                </ul>

                <ul class="qe-toolbar__links">
                    <li class="btn__search">
                        <form action="search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" accesskey="k">
                            <i data-feather="search" id="search-icon"></i>
                        </form>
                    </li>
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="/_notebooks/lln_clt.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li class="download-pdf" id="downloadButton"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python.myst/blob/main/lectures/lln_clt.md" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="/_pdf/quantecon-python.pdf" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://colab.research.google.com/github/QuantEcon/lecture-python.notebooks/blob/master/lln_clt.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-python.notebooks" data-urlpath="tree/lecture-python.notebooks/lln_clt.ipynb" data-branch=master>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://colab.research.google.com/github/QuantEcon/lecture-python.notebooks/blob/master/lln_clt.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "lln_clt";
                const repoURL = "https://github.com/QuantEcon/lecture-python.notebooks";
                const urlPath = "tree/lecture-python.notebooks/lln_clt.ipynb";
                const branch = "master"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>