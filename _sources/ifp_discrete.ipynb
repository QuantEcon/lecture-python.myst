{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9c95c5",
   "metadata": {},
   "source": [
    "# The Income Fluctuation Problem I: Discretization and VFI\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "In this lecture, we study an optimal savings problem for an infinitely lived consumer---the \"common ancestor\" described in {cite}`Ljungqvist2012`, section 1.3.\n",
    "\n",
    "This savings problem is often called an **income fluctuation problem** or a **household problem**.\n",
    "\n",
    "It is an essential sub-problem for many representative macroeconomic models\n",
    "\n",
    "* {cite}`Aiyagari1994`\n",
    "* {cite}`Huggett1993`\n",
    "* etc.\n",
    "\n",
    "It is related to the decision problem in {doc}`os_stochastic` but differs in significant ways.\n",
    "\n",
    "For example, \n",
    "\n",
    "1. The choice problem for the agent includes an additive income term that leads to an occasionally binding constraint.\n",
    "2. Shocks affecting the budget constraint are correlated, forcing us to track an extra state variable.\n",
    "\n",
    "We will begin by working with a relatively basic version of the model and\n",
    "solving it via old-fashioned discretization + value function iteration.\n",
    "\n",
    "Although this approach is not the fastest or the most efficient, it is very\n",
    "robust and flexible.\n",
    "\n",
    "For example, if we suddenly decided to add [Epstein--Zin preferences](https://en.wikipedia.org/wiki/Epstein%E2%80%93Zin_preferences), or\n",
    "modify ordinary conditional expectations to quantiles, the technique would\n",
    "continue to work well.\n",
    "\n",
    "```{note}\n",
    "The same is not true of some other methods we will deploy, such as the\n",
    "endogenous grid method.\n",
    "\n",
    "This is a general rule of computation and analysis --- while we can often come up with\n",
    "faster algorithms by exploiting structure, these new algorithms are typically less\n",
    "robust.\n",
    "\n",
    "They are less robust precisely because they exploit more structure --- which\n",
    "implies that they are, inevitably, more vulnerable to change.\n",
    "```\n",
    "\n",
    "In addition to Anaconda, this lecture will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ea7d7",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install quantecon jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b00edf",
   "metadata": {},
   "source": [
    "We will use the following imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8417c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantecon as qe\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import NamedTuple\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29281725",
   "metadata": {},
   "source": [
    "We'll use 64 bit floats to gain extra precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81124d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09517d6a",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "\n",
    "We study a household that chooses a state-contingent consumption plan $\\{c_t\\}_{t \\geq 0}$ to maximize\n",
    "\n",
    "$$\n",
    "\\mathbb{E} \\, \\sum_{t=0}^{\\infty} \\beta^t u(c_t)\n",
    "$$\n",
    "\n",
    "subject to\n",
    "\n",
    "$$\n",
    "    a_{t+1} + c_t \\leq R a_t + y_t\n",
    "$$\n",
    "\n",
    "Here\n",
    "\n",
    "* $c_t$ is consumption and $c_t \\geq 0$,\n",
    "* $a_t$ is assets and $a_t \\geq 0$,\n",
    "* $R = 1 + r$ is a gross rate of return, and\n",
    "* $(y_t)_{t \\geq 0}$ is labor income, taking values in some finite set $\\mathsf Y$.\n",
    "\n",
    "We assume below that labor income dynamics follow a discretized AR(1) process.\n",
    "\n",
    "We set $\\mathsf S := \\mathbb{R}_+ \\times \\mathsf Y$, which represents the state\n",
    "space.\n",
    "\n",
    "The **value function** $V \\colon \\mathsf S \\to \\mathbb{R}$ is defined by\n",
    "\n",
    "```{math}\n",
    ":label: eqvfs\n",
    "\n",
    "V(a, y) := \\max \\, \\mathbb{E}\n",
    "\\left\\{\n",
    "\\sum_{t=0}^{\\infty} \\beta^t u(c_t)\n",
    "\\right\\}\n",
    "```\n",
    "\n",
    "where the maximization is over all feasible consumption sequences given $(a_0,\n",
    "y_0) = (a, y)$.\n",
    "\n",
    "The Bellman equation is\n",
    "\n",
    "$$   \n",
    "    v(a, y) = \\max_{0 \\leq a' \\leq Ra + y}\n",
    "    \\left\\{\n",
    "        u(Ra + y - a') + β \\sum_{y'} v(a', y') Q(y, y') \n",
    "    \\right\\}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "    u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma} \n",
    "$$\n",
    "\n",
    "In the code we use the function\n",
    "\n",
    "$$   \n",
    "    B((a, y), a', v) = u(Ra + y - a') + β \\sum_{y'} v(a', y') Q(y, y'). \n",
    "$$\n",
    "\n",
    "the encapsulate the right hand side of the Bellman equation.\n",
    "\n",
    "\n",
    "\n",
    "## Code\n",
    "\n",
    "The following code defines a `NamedTuple` to store the model parameters and grids.\n",
    "\n",
    "(prgm:create-consumption-model)="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(NamedTuple):\n",
    "    β: float              # Discount factor\n",
    "    R: float              # Gross interest rate\n",
    "    γ: float              # CRRA parameter\n",
    "    a_grid: jnp.ndarray   # Asset grid\n",
    "    y_grid: jnp.ndarray   # Income grid\n",
    "    Q: jnp.ndarray        # Markov matrix for income\n",
    "\n",
    "\n",
    "def create_consumption_model(\n",
    "        R=1.01,                    # Gross interest rate\n",
    "        β=0.98,                    # Discount factor\n",
    "        γ=2,                       # CRRA parameter\n",
    "        a_min=0.01,                # Min assets\n",
    "        a_max=5.0,                 # Max assets\n",
    "        a_size=150,                # Grid size\n",
    "        ρ=0.9, ν=0.1, y_size=100   # Income parameters\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Creates an instance of the consumption-savings model.\n",
    "\n",
    "    \"\"\"\n",
    "    a_grid = jnp.linspace(a_min, a_max, a_size)\n",
    "    mc = qe.tauchen(n=y_size, rho=ρ, sigma=ν)\n",
    "    y_grid, Q = jnp.exp(mc.state_values), jax.device_put(mc.P)\n",
    "    return Model(β, R, γ, a_grid, y_grid, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8ac5b",
   "metadata": {},
   "source": [
    "Now we define the right hand side of the Bellman equation.\n",
    "\n",
    "We'll use a vectorized coding style reminiscent of Matlab and NumPy (avoiding all loops).\n",
    "\n",
    "Your are invited to explore an alternative style based around `jax.vmap` in the Exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb6fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def B(v, model):\n",
    "    \"\"\"\n",
    "    A vectorized version of the right-hand side of the Bellman equation\n",
    "    (before maximization), which is a 3D array representing\n",
    "\n",
    "        B(a, y, a′) = u(Ra + y - a′) + β Σ_y′ v(a′, y′) Q(y, y′)\n",
    "\n",
    "    for all (a, y, a′).\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack\n",
    "    β, R, γ, a_grid, y_grid, Q = model\n",
    "    a_size, y_size = len(a_grid), len(y_grid)\n",
    "\n",
    "    # Compute current rewards r(a, y, ap) as array r[i, j, ip]\n",
    "    a  = jnp.reshape(a_grid, (a_size, 1, 1))    # a[i]   ->  a[i, j, ip]\n",
    "    y  = jnp.reshape(y_grid, (1, y_size, 1))    # z[j]   ->  z[i, j, ip]\n",
    "    ap = jnp.reshape(a_grid, (1, 1, a_size))    # ap[ip] -> ap[i, j, ip]\n",
    "    c = R * a + y - ap\n",
    "\n",
    "    # Calculate continuation rewards at all combinations of (a, y, ap)\n",
    "    v = jnp.reshape(v, (1, 1, a_size, y_size))  # v[ip, jp] -> v[i, j, ip, jp]\n",
    "    Q = jnp.reshape(Q, (1, y_size, 1, y_size))  # Q[j, jp]  -> Q[i, j, ip, jp]\n",
    "    EV = jnp.sum(v * Q, axis=3)                 # sum over last index jp\n",
    "\n",
    "    # Compute the right-hand side of the Bellman equation\n",
    "    return jnp.where(c > 0, c**(1-γ)/(1-γ) + β * EV, -jnp.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e3f967",
   "metadata": {},
   "source": [
    "Some readers might be concerned that we are creating high dimensional arrays,\n",
    "leading to inefficiency.\n",
    "\n",
    "Could they be avoided by more careful vectorization?\n",
    "\n",
    "In fact this is not necessary: this function will be JIT-compiled by JAX, and\n",
    "the JIT compiler will optimize compiled code to minimize memory use.\n",
    "\n",
    "The Bellman operator $T$ can be implemented by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def T(v, model):\n",
    "    \"The Bellman operator.\"\n",
    "    return jnp.max(B(v, model), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd821e",
   "metadata": {},
   "source": [
    "The next function computes a $v$-greedy policy given $v$ (i.e., the policy that\n",
    "maximizes the right-hand side of the Bellman equation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def get_greedy(v, model):\n",
    "    \"Computes a v-greedy policy, returned as a set of indices.\"\n",
    "    return jnp.argmax(B(v, model), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb44cc",
   "metadata": {},
   "source": [
    "### Value function iteration\n",
    "\n",
    "Now we define a solver that implements VFI.\n",
    "\n",
    "First we write a simple version using a standard Python loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_function_iteration_python(model, tol=1e-5, max_iter=10_000):\n",
    "    \"\"\"\n",
    "    Implements VFI using successive approximation with a Python loop.\n",
    "    \"\"\"\n",
    "    v = jnp.zeros((len(model.a_grid), len(model.y_grid)))\n",
    "    error = tol + 1\n",
    "    k = 0\n",
    "\n",
    "    while error > tol and k < max_iter:\n",
    "        v_new = T(v, model)\n",
    "        error = jnp.max(jnp.abs(v_new - v))\n",
    "        v = v_new\n",
    "        k += 1\n",
    "\n",
    "    return v, get_greedy(v, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f58a46",
   "metadata": {},
   "source": [
    "Next we write a version that uses `jax.lax.while_loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47873348",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def value_function_iteration(model, tol=1e-5, max_iter=10_000):\n",
    "    \"\"\"\n",
    "    Implements VFI using successive approximation.\n",
    "    \"\"\"\n",
    "    def body_fun(k_v_err):\n",
    "        k, v, error = k_v_err\n",
    "        v_new = T(v, model)\n",
    "        error = jnp.max(jnp.abs(v_new - v))\n",
    "        return k + 1, v_new, error\n",
    "\n",
    "    def cond_fun(k_v_err):\n",
    "        k, v, error = k_v_err\n",
    "        return jnp.logical_and(error > tol, k < max_iter)\n",
    "\n",
    "    v_init = jnp.zeros((len(model.a_grid), len(model.y_grid)))\n",
    "    k, v_star, error = jax.lax.while_loop(cond_fun, body_fun,\n",
    "                                          (1, v_init, tol + 1))\n",
    "    return v_star, get_greedy(v_star, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8a1b3",
   "metadata": {},
   "source": [
    "### Timing\n",
    "\n",
    "Let's create an instance and compare the two implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_consumption_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4cae6",
   "metadata": {},
   "source": [
    "First let's time the Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting VFI using Python loop.\")\n",
    "start = time()\n",
    "v_star_python, σ_star_python = value_function_iteration_python(model)\n",
    "python_time = time() - start\n",
    "print(f\"VFI completed in {python_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9011133",
   "metadata": {},
   "source": [
    "Now let's time the `jax.lax.while_loop` version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting VFI using jax.lax.while_loop.\")\n",
    "start = time()\n",
    "v_star_jax, σ_star_jax = value_function_iteration(model)\n",
    "v_star_jax.block_until_ready()\n",
    "jax_with_compile = time() - start\n",
    "print(f\"VFI completed in {jax_with_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297216b9",
   "metadata": {},
   "source": [
    "Let's run it again to eliminate compile time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43da9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "v_star_jax, σ_star_jax = value_function_iteration(model)\n",
    "v_star_jax.block_until_ready()\n",
    "jax_without_compile = time() - start\n",
    "print(f\"VFI completed in {jax_without_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f418aec",
   "metadata": {},
   "source": [
    "Let's check that the two implementations produce the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26da59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Values match: {jnp.allclose(v_star_python, v_star_jax)}\")\n",
    "print(f\"Policies match: {jnp.allclose(σ_star_python, σ_star_jax)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6124632",
   "metadata": {},
   "source": [
    "Here's the speedup from using `jax.lax.while_loop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0545a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Relative speed = {python_time / jax_without_compile:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cbdb4",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "```{exercise}\n",
    ":label: ifp_ex1\n",
    "\n",
    "In this exercise, we explore an alternative approach to implementing value function iteration using `jax.vmap`.\n",
    "\n",
    "For this simple optimal savings problem, direct vectorization is relatively easy.\n",
    "\n",
    "In particular, it's straightforward to express the right hand side of the\n",
    "Bellman equation as an array that stores evaluations of the function at every\n",
    "state and control.\n",
    "\n",
    "However, for more complex models, direct vectorization can be much harder.\n",
    "\n",
    "For this reason, it helps to have another approach to fast JAX implementations\n",
    "up our sleeves.\n",
    "\n",
    "Your task is to implement a version that:\n",
    "\n",
    "1. writes the right hand side of the Bellman operator as a function of individual states and controls, and\n",
    "2. applies `jax.vmap` on the outside to achieve a parallelized solution.\n",
    "\n",
    "Specifically:\n",
    "\n",
    "1. Rewrite `B` to take indices `(i, j, ip)` corresponding to `(a, y, a′)` and compute the Bellman equation for those specific indices.\n",
    "2. Use `jax.vmap` successively to vectorize over all indices (use staged vmap as shown in earlier examples).\n",
    "3. Implement `T_vmap` and `get_greedy_vmap` functions using the vectorized `B`.\n",
    "4. Implement `value_iteration_vmap` using `jax.lax.while_loop`.\n",
    "5. Test that your implementation produces the same results as the direct vectorization approach.\n",
    "6. Compare the execution times of both approaches.\n",
    "```\n",
    "\n",
    "```{solution-start} ifp_ex1\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "Here's one solution.\n",
    "\n",
    "First let's rewrite `B` to work with individual indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B(v, model, i, j, ip):\n",
    "    \"\"\"\n",
    "    The right-hand side of the Bellman equation before maximization, which takes\n",
    "    the form\n",
    "\n",
    "        B(a, y, a′) = u(Ra + y - a′) + β Σ_y′ v(a′, y′) Q(y, y′)\n",
    "\n",
    "    The indices are (i, j, ip) -> (a, y, a′).\n",
    "    \"\"\"\n",
    "    β, R, γ, a_grid, y_grid, Q = model\n",
    "    a, y, ap  = a_grid[i], y_grid[j], a_grid[ip]\n",
    "    c = R * a + y - ap\n",
    "    EV = jnp.sum(v[ip, :] * Q[j, :])\n",
    "    return jnp.where(c > 0, c**(1-γ)/(1-γ) + β * EV, -jnp.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd10e47",
   "metadata": {},
   "source": [
    "Now we successively apply `vmap` to simulate nested loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_1    = jax.vmap(B,   in_axes=(None, None, None, None, 0))\n",
    "B_2    = jax.vmap(B_1, in_axes=(None, None, None, 0,    None))\n",
    "B_vmap = jax.vmap(B_2, in_axes=(None, None, 0,    None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d8624f",
   "metadata": {},
   "source": [
    "Here's the Bellman operator and the `get_greedy` functions for the `vmap` case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a03d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def T_vmap(v, model):\n",
    "    \"The Bellman operator.\"\n",
    "    a_indices = jnp.arange(len(model.a_grid))\n",
    "    y_indices = jnp.arange(len(model.y_grid))\n",
    "    B_values = B_vmap(v, model, a_indices, y_indices, a_indices)\n",
    "    return jnp.max(B_values, axis=-1)\n",
    "\n",
    "@jax.jit\n",
    "def get_greedy_vmap(v, model):\n",
    "    \"Computes a v-greedy policy, returned as a set of indices.\"\n",
    "    a_indices = jnp.arange(len(model.a_grid))\n",
    "    y_indices = jnp.arange(len(model.y_grid))\n",
    "    B_values = B_vmap(v, model, a_indices, y_indices, a_indices)\n",
    "    return jnp.argmax(B_values, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e6b00",
   "metadata": {},
   "source": [
    "Here's the iteration routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d9474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration_vmap(model, tol=1e-5, max_iter=10_000):\n",
    "    \"\"\"\n",
    "    Implements VFI using vmap and successive approximation.\n",
    "    \"\"\"\n",
    "    def body_fun(k_v_err):\n",
    "        k, v, error = k_v_err\n",
    "        v_new = T_vmap(v, model)\n",
    "        error = jnp.max(jnp.abs(v_new - v))\n",
    "        return k + 1, v_new, error\n",
    "\n",
    "    def cond_fun(k_v_err):\n",
    "        k, v, error = k_v_err\n",
    "        return jnp.logical_and(error > tol, k < max_iter)\n",
    "\n",
    "    v_init = jnp.zeros((len(model.a_grid), len(model.y_grid)))\n",
    "    k, v_star, error = jax.lax.while_loop(cond_fun, body_fun,\n",
    "                                          (1, v_init, tol + 1))\n",
    "    return v_star, get_greedy_vmap(v_star, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82bba23",
   "metadata": {},
   "source": [
    "Let's see how long it takes to solve the model using the `vmap` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting VFI using vmap.\")\n",
    "start = time()\n",
    "v_star_vmap, σ_star_vmap = value_iteration_vmap(model)\n",
    "v_star_vmap.block_until_ready()\n",
    "jax_vmap_with_compile = time() - start\n",
    "print(f\"VFI completed in {jax_vmap_with_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee5db0",
   "metadata": {},
   "source": [
    "Let's run it again to get rid of compile time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ff3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "v_star_vmap, σ_star_vmap = value_iteration_vmap(model)\n",
    "v_star_vmap.block_until_ready()\n",
    "jax_vmap_without_compile = time() - start\n",
    "print(f\"VFI completed in {jax_vmap_without_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503349f",
   "metadata": {},
   "source": [
    "We need to make sure that we got the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1eb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jnp.allclose(v_star_vmap, v_star_jax))\n",
    "print(jnp.allclose(σ_star_vmap, σ_star_jax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9210649",
   "metadata": {},
   "source": [
    "Here's the comparison with the first JAX implementation (which used direct vectorization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451bef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Relative speed = {jax_without_compile / jax_vmap_without_compile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93a8c2",
   "metadata": {},
   "source": [
    "The execution times for the two JAX versions are relatively similar.\n",
    "\n",
    "However, as emphasized above, having a second method up our sleeves (i.e, the\n",
    "`vmap` approach) will be helpful when confronting dynamic programs with more\n",
    "sophisticated Bellman equations.\n",
    "\n",
    "```{solution-end}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.16.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   61,
   65,
   69,
   76,
   81,
   83,
   156,
   183,
   191,
   220,
   232,
   237,
   242,
   247,
   256,
   272,
   276,
   296,
   302,
   304,
   308,
   314,
   318,
   325,
   329,
   335,
   339,
   342,
   346,
   348,
   392,
   407,
   411,
   415,
   419,
   435,
   439,
   458,
   462,
   469,
   473,
   479,
   483,
   486,
   490,
   492
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}