{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a8ca6d",
   "metadata": {},
   "source": [
    "# QR Decomposition\n",
    "\n",
    "## Overview\n",
    "\n",
    "This lecture describes the QR decomposition and how it relates to\n",
    "\n",
    " * Orthogonal projection and least squares\n",
    "\n",
    " * A Gram-Schmidt process\n",
    "\n",
    " * Eigenvalues and eigenvectors\n",
    "\n",
    "\n",
    "We'll write some Python code to help consolidate our understandings.\n",
    "\n",
    "## Matrix Factorization\n",
    "\n",
    "The QR decomposition (also called the QR factorization) of a matrix is a decomposition of a matrix into the product of  an orthogonal matrix and a triangular matrix.\n",
    "\n",
    "A QR decomposition of a real  matrix $A$ \n",
    "takes the form \n",
    "\n",
    "$$\n",
    "A=QR\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "* $Q$ is an orthogonal matrix (so that  $Q^TQ = I$)\n",
    "\n",
    "* $R$ is an upper triangular matrix \n",
    "\n",
    "\n",
    "We'll use a **Gram-Schmidt process** to compute a  QR decomposition \n",
    "\n",
    "Because doing so is so educational, we'll  write our own Python code to do the job\n",
    "\n",
    "## Gram-Schmidt process\n",
    "\n",
    "We'll start with a **square** matrix $A$.\n",
    "\n",
    "If a square matrix $A$ is nonsingular, then a $QR$ factorization is unique.\n",
    "\n",
    "We'll deal with a rectangular matrix $A$ later.\n",
    "\n",
    "Actually, our algorithm will work with a rectangular $A$ that is not square.\n",
    "\n",
    "### Gram-Schmidt process for square $A$\n",
    "\n",
    "Here we apply a Gram-Schmidt  process to the  **columns**  of matrix $A$.\n",
    "\n",
    "In particular, let\n",
    "\n",
    "$$\n",
    "A= \\left[ \\begin{array}{c|c|c|c} a_1 & a_2 & \\cdots & a_n \\end{array} \\right]\n",
    "$$\n",
    "\n",
    "Let $|| 路 ||$ denote the L2 norm.\n",
    "\n",
    "The Gram-Schmidt algorithm repeatedly combines the following  two steps in a particular order\n",
    "\n",
    "*  **normalize** a vector to have unit norm\n",
    "\n",
    "*  **orthogonalize** the next vector\n",
    "\n",
    "To begin, we set $u_1 = a_1$ and then **normalize**:\n",
    "\n",
    "$$\n",
    "u_1=a_1, \\ \\ \\ e_1=\\frac{u_1}{||u_1||}\n",
    "$$\n",
    "\n",
    "We **orgonalize** first to compute $u_2$ and then **normalize** to create $e_2$:\n",
    "\n",
    "$$\n",
    "u_2=a_2-(a_2路 e_1)e_1, \\ \\ \\  e_2=\\frac{u_2}{||u_2||}\n",
    "$$\n",
    "\n",
    "We invite the reader to verify that $e_1$ is orthogonal to $e_2$ by checking that\n",
    "$e_1 \\cdot e_2 = 0$.\n",
    "\n",
    "The Gram-Schmidt procedure continues iterating.\n",
    "\n",
    "Thus,  for $k= 2, \\ldots, n-1$ we construct\n",
    "\n",
    "$$\n",
    "u_{k+1}=a_{k+1}-(a_{k+1}路 e_1)e_1-\\cdots-(a_{k+1}路 e_k)e_k, \\ \\ \\ e_{k+1}=\\frac{u_{k+1}}{||u_{k+1}||}\n",
    "$$\n",
    "\n",
    "\n",
    "Here $(a_j \\cdot e_i)$ can be interpreted as the linear least squares **regression coefficient** of $a_j$ on $e_i$ \n",
    "\n",
    "* it is the inner product of $a_j$ and $e_i$ divided by the inner product of $e_i$ where \n",
    "    $e_i \\cdot e_i = 1$, as *normalization* has assured us.\n",
    "    \n",
    "* this regression coefficient has an interpretation as being  a **covariance** divided by a **variance**\n",
    "   \n",
    "\n",
    "It can  be verified that\n",
    "\n",
    "$$\n",
    "A= \\left[ \\begin{array}{c|c|c|c} a_1 & a_2 & \\cdots & a_n \\end{array} \\right]=\n",
    "\\left[ \\begin{array}{c|c|c|c} e_1 & e_2 & \\cdots & e_n \\end{array} \\right]\n",
    "\\left[ \\begin{matrix} a_1路e_1 & a_2路e_1 & \\cdots & a_n路e_1\\\\ 0 & a_2路e_2 & \\cdots & a_n路e_2 \n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & a_n路e_n \\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    "Thus, we have constructed the decomposision\n",
    "\n",
    "$$ \n",
    "A = Q R\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$ \n",
    "Q = \\left[ \\begin{array}{c|c|c|c} a_1 & a_2 & \\cdots & a_n \\end{array} \\right]=\n",
    "\\left[ \\begin{array}{c|c|c|c} e_1 & e_2 & \\cdots & e_n \\end{array} \\right]\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "R = \\left[ \\begin{matrix} a_1路e_1 & a_2路e_1 & \\cdots & a_n路e_1\\\\ 0 & a_2路e_2 & \\cdots & a_n路e_2 \n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & \\cdots & a_n路e_n \\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    "### $A$ not square \n",
    "\n",
    "Now suppose that $A$ is an $n \\times m$ matrix where $m > n$.  \n",
    "\n",
    "Then a $QR$ decomposition is\n",
    "\n",
    "$$\n",
    "A= \\left[ \\begin{array}{c|c|c|c} a_1 & a_2 & \\cdots & a_m \\end{array} \\right]=\\left[ \\begin{array}{c|c|c|c} e_1 & e_2 & \\cdots & e_n \\end{array} \\right]\n",
    "\\left[ \\begin{matrix} a_1路e_1 & a_2路e_1 & \\cdots & a_n路e_1 & a_{n+1}\\cdot e_1 & \\cdots & a_{m}\\cdot e_1 \\\\\n",
    "0 & a_2路e_2 & \\cdots & a_n路e_2 & a_{n+1}\\cdot e_2 & \\cdots & a_{m}\\cdot e_2 \\\\ \\vdots & \\vdots & \\ddots & \\quad  \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\cdots & a_n路e_n & a_{n+1}\\cdot e_n & \\cdots & a_{m}\\cdot e_n \\end{matrix} \\right]\n",
    "$$\n",
    "\n",
    "which implies that\n",
    "\n",
    "\\begin{align*}\n",
    "a_1 & = (a_1\\cdot e_1) e_1 \\cr\n",
    "a_2 & = (a_2\\cdot e_1) e_1 + (a_2\\cdot e_2) e_2 \\cr\n",
    "\\vdots & \\quad \\vdots \\cr\n",
    "a_n & = (a_n\\cdot e_1) e_1 + (a_n\\cdot e_2) e_2 + \\cdots + (a_n \\cdot e_n) e_n  \\cr\n",
    "a_{n+1} & = (a_{n+1}\\cdot e_1) e_1 + (a_{n+1}\\cdot e_2) e_2 + \\cdots + (a_{n+1}\\cdot e_n) e_n  \\cr\n",
    "\\vdots & \\quad \\vdots \\cr\n",
    "a_m & = (a_m\\cdot e_1) e_1 + (a_m\\cdot e_2) e_2 + \\cdots + (a_m \\cdot e_n) e_n  \\cr\n",
    "\\end{align*}\n",
    "\n",
    "## Some Code\n",
    "\n",
    "Now let's write some homemade Python code to implement a QR decomposition by deploying the  Gram-Schmidt process described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4756f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8489bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_Decomposition(A):\n",
    "    n, m = A.shape # get the shape of A\n",
    "\n",
    "    Q = np.empty((n, n)) # initialize matrix Q\n",
    "    u = np.empty((n, n)) # initialize matrix u\n",
    "\n",
    "    u[:, 0] = A[:, 0]\n",
    "    Q[:, 0] = u[:, 0] / np.linalg.norm(u[:, 0])\n",
    "\n",
    "    for i in range(1, n):\n",
    "\n",
    "        u[:, i] = A[:, i]\n",
    "        for j in range(i):\n",
    "            u[:, i] -= (A[:, i] @ Q[:, j]) * Q[:, j] # get each u vector\n",
    "\n",
    "        Q[:, i] = u[:, i] / np.linalg.norm(u[:, i]) # compute each e vetor\n",
    "\n",
    "    R = np.zeros((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(i, m):\n",
    "            R[i, j] = A[:, j] @ Q[:, i]\n",
    "\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa73edb",
   "metadata": {},
   "source": [
    "The preceding code is fine but can benefit from some further housekeeping.\n",
    "\n",
    "We want to do this because later in this notebook we want to compare results from using our homemade code above with the code for a QR that the Python `scipy` package delivers.\n",
    "\n",
    "There can be be sign differences between the $Q$ and $R$ matrices produced by different numerical algorithms.\n",
    "\n",
    "All of these are valid QR decompositions because of how the  sign differences cancel out when we compute $QR$.\n",
    "\n",
    "However, to make the results from  our homemade function and the QR module in `scipy` comparable, let's require that $Q$ have positive diagonal entries.\n",
    "\n",
    "We do this by adjusting  the signs of the columns in $Q$ and the rows in $R$ appropriately.\n",
    "\n",
    "To accomplish this we'll define a pair of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f666f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_sign(A):\n",
    "    \"Compute the signs of the diagonal of matrix A\"\n",
    "\n",
    "    D = np.diag(np.sign(np.diag(A)))\n",
    "\n",
    "    return D\n",
    "\n",
    "def adjust_sign(Q, R):\n",
    "    \"\"\"\n",
    "    Adjust the signs of the columns in Q and rows in R to\n",
    "    impose positive diagonal of Q\n",
    "    \"\"\"\n",
    "\n",
    "    D = diag_sign(Q)\n",
    "\n",
    "    Q[:, :] = Q @ D\n",
    "    R[:, :] = D @ R\n",
    "\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edd15c8",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Now let's do an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f33af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1.0, 1.0, 0.0], [1.0, 0.0, 1.0], [0.0, 1.0, 1.0]])\n",
    "# A = np.array([[1.0, 0.5, 0.2], [0.5, 0.5, 1.0], [0.0, 1.0, 1.0]])\n",
    "# A = np.array([[1.0, 0.5, 0.2], [0.5, 0.5, 1.0]])\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24731cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, R = adjust_sign(*QR_Decomposition(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9ac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e696853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6cdad",
   "metadata": {},
   "source": [
    "Let's compare outcomes  with what the `scipy` package produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc358717",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_scipy, R_scipy = adjust_sign(*qr(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our Q: \\n', Q)\n",
    "print('\\n')\n",
    "print('Scipy Q: \\n', Q_scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our R: \\n', R)\n",
    "print('\\n')\n",
    "print('Scipy R: \\n', R_scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa8d67",
   "metadata": {},
   "source": [
    "The above outcomes give us the good news that our homemade function agrees with what\n",
    "scipy produces.\n",
    "\n",
    "\n",
    "Now let's do a QR decomposition for a rectangular matrix $A$ that is $n \\times m$ with \n",
    "$m > n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 3, 4], [2, 0, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, R = adjust_sign(*QR_Decomposition(A))\n",
    "Q, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_scipy, R_scipy = adjust_sign(*qr(A))\n",
    "Q_scipy, R_scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c5403",
   "metadata": {},
   "source": [
    "## Using QR Decomposition to Compute Eigenvalues\n",
    "\n",
    "Now for a useful  fact about the QR algorithm.  \n",
    "\n",
    "The following iterations on the QR decomposition can be used to compute **eigenvalues**\n",
    "of a **square** matrix $A$.\n",
    "\n",
    "Here is the algorithm:\n",
    "\n",
    "1. Set $A_0 = A$ and form $A_0 = Q_0 R_0$\n",
    "\n",
    "2. Form $A_1 = R_0 Q_0 $ . Note that $A_1$ is similar to $A_0$ (easy to verify) and so has the same eigenvalues.\n",
    "\n",
    "3. Form $A_1 = Q_1 R_1$ (i.e., form the $QR$ decomposition of $A_1$).\n",
    "\n",
    "4. Form $ A_2 = R_1 Q_1 $ and then $A_2 = Q_2 R_2$  .\n",
    "\n",
    "5. Iterate to convergence.\n",
    "\n",
    "6. Compute eigenvalues of $A$ and compare them to the diagonal values of the limiting $A_n$ found from this process.\n",
    "\n",
    "```{todo}\n",
    "@mmcky to migrate this to use [sphinx-proof](https://sphinx-proof.readthedocs.io/en/latest/syntax.html#algorithms)\n",
    "```\n",
    "\n",
    "**Remark:** this algorithm is close to one of the most efficient ways of computing eigenvalues!\n",
    "\n",
    "Let's write some Python code to try out the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_eigvals(A, tol=1e-12, maxiter=1000):\n",
    "    \"Find the eigenvalues of A using QR decomposition.\"\n",
    "\n",
    "    A_old = np.copy(A)\n",
    "    A_new = np.copy(A)\n",
    "\n",
    "    diff = np.inf\n",
    "    i = 0\n",
    "    while (diff > tol) and (i < maxiter):\n",
    "        A_old[:, :] = A_new\n",
    "        Q, R = QR_Decomposition(A_old)\n",
    "\n",
    "        A_new[:, :] = R @ Q\n",
    "\n",
    "        diff = np.abs(A_new - A_old).max()\n",
    "        i += 1\n",
    "\n",
    "    eigvals = np.diag(A_new)\n",
    "\n",
    "    return eigvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529dd55a",
   "metadata": {},
   "source": [
    "Now let's try the code and compare the results with what `scipy.linalg.eigvals` gives us\n",
    "\n",
    "Here goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment this with one random A matrix\n",
    "A = np.random.random((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc337eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(QR_eigvals(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58882d4d",
   "metadata": {},
   "source": [
    "Compare with the `scipy` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(np.linalg.eigvals(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a59a9",
   "metadata": {},
   "source": [
    "## $QR$ and PCA\n",
    "\n",
    "There are interesting connections between the $QR$ decomposition and principal components analysis (PCA).\n",
    "\n",
    "Here are  some.\n",
    "\n",
    "1.  Let $X'$ be a $k \\times n$ random matrix where the $j$th column is a random draw\n",
    "from ${\\mathcal N}(\\mu, \\Sigma)$ where $\\mu$ is $k \\times 1$ vector of means and $\\Sigma$ is a $k \\times k$\n",
    "covariance matrix.  We want $n > > k$ -- this is an \"econometrics example\".\n",
    "\n",
    "2. Form $X' = Q R $ where $Q $ is $k \\times k$ and $R$ is $k \\times n$.\n",
    "\n",
    "3. Form the eigenvalues of $ R R'$, i.e., we'll compute $R R' = \\tilde P \\Lambda \\tilde P' $.\n",
    "\n",
    "4. Form $X' X = Q \\tilde P \\Lambda \\tilde P' Q'$ and compare it with the eigen decomposition\n",
    "$ X'X = P \\hat \\Lambda P'$.  \n",
    "\n",
    "5. It will turn out that  that $\\Lambda = \\hat \\Lambda$ and that $P = Q \\tilde P$.\n",
    "\n",
    "\n",
    "Let's verify conjecture 5 with some Python code.\n",
    "\n",
    "Start by simulating a random $\\left(n, k\\right)$ matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11690b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "n = 1000\n",
    "\n",
    "# generate some random moments\n",
    " = np.random.random(size=k)\n",
    "C = np.random.random((k, k))\n",
    "危 = C.T @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is random matrix where each column follows multivariate normal dist.\n",
    "X = np.random.multivariate_normal(, 危, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4e41ed",
   "metadata": {},
   "source": [
    "Let's apply the QR decomposition to $X^{\\prime}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, R = adjust_sign(*QR_Decomposition(X.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490f2d7",
   "metadata": {},
   "source": [
    "Check the shapes of $Q$ and $R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape, R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5707c9b",
   "metadata": {},
   "source": [
    "Now we can construct $R R^{\\prime}=\\tilde{P} \\Lambda \\tilde{P}^{\\prime}$ and form an eigen decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad58613",
   "metadata": {},
   "outputs": [],
   "source": [
    "RR = R @ R.T\n",
    "\n",
    ", P_tilde = np.linalg.eigh(RR)\n",
    " = np.diag()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb635096",
   "metadata": {},
   "source": [
    "We can also apply the decomposition to $X^{\\prime} X=P \\hat{\\Lambda} P^{\\prime}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad332a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = X.T @ X\n",
    "\n",
    "_hat, P = np.linalg.eigh(XX)\n",
    "_hat = np.diag(_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46080aa",
   "metadata": {},
   "source": [
    "Compare the eigenvalues that are on the diagonals of $\\Lambda$ and $\\hat{\\Lambda}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7435f",
   "metadata": {},
   "outputs": [],
   "source": [
    ", _hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04063b32",
   "metadata": {},
   "source": [
    "Let's compare $P$ and $Q \\tilde{P}$. \n",
    "\n",
    "Again we need to be careful about sign differences between the columns of $P$ and $Q\\tilde{P}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c072d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "QP_tilde = Q @ P_tilde\n",
    "\n",
    "np.abs(P @ diag_sign(P) - QP_tilde @ diag_sign(QP_tilde)).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d83385",
   "metadata": {},
   "source": [
    "Let's verify that $X^{\\prime}X$ can be decomposed as $Q \\tilde{P} \\Lambda \\tilde{P}^{\\prime} Q^{\\prime}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QPPQ = Q @ P_tilde @  @ P_tilde.T @ Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec082e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(QPPQ - XX).max()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   12,
   169,
   174,
   198,
   214,
   234,
   240,
   248,
   252,
   256,
   258,
   262,
   266,
   272,
   276,
   285,
   289,
   294,
   297,
   328,
   349,
   355,
   360,
   362,
   366,
   368,
   394,
   404,
   409,
   411,
   415,
   417,
   421,
   423,
   427,
   432,
   436,
   441,
   445,
   447,
   453,
   457,
   461,
   465
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}