

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>18. Non-Conjugate Priors &#8212; Intermediate Quantitative Economics with Python</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/quantecon-book-theme.css?digest=bd0785fbb14d8d2bd4d9ae501d79ed8d3bc089ec" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>


    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/scripts/quantecon-book-theme.js?digest=d6d86bce9979111653c4c495e33499e1796e172a"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-J0SMYR4SG3"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-J0SMYR4SG3');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "arg\\,max", "argmin": "arg\\,min"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'bayes_nonconj';</script>
    <link rel="canonical" href="https://python.quantecon.org/bayes_nonconj.html" />
    <link rel="shortcut icon" href="_static/lectures-favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="19. Posterior Distributions for AR(1) Parameters" href="ar1_bayes.html" />
    <link rel="prev" title="17. Expected Utilities of Random Responses" href="util_rand_resp.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Python, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Non-Conjugate Priors"/>
<meta name="twitter:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Non-Conjugate Priors" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://python.quantecon.org/bayes_nonconj.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski." />
<meta property="og:site_name" content="Intermediate Quantitative Economics with Python" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=bayes_nonconj>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#unleashing-mcmc-on-a-binomial-likelihood">18.1. Unleashing MCMC on a  Binomial Likelihood</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analytical-posterior">18.1.1. Analytical Posterior</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-ways-to-approximate-posteriors">18.1.2. Two Ways to Approximate Posteriors</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-distributions">18.2. Prior Distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-inference">18.2.1. Variational Inference</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">18.3. Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alternative-prior-distributions">18.4. Alternative Prior Distributions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#posteriors-via-mcmc-and-vi">18.5. Posteriors Via MCMC and VI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#beta-prior-and-posteriors">18.5.1. Beta Prior and Posteriors:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-conjugate-prior-distributions">18.6. Non-conjugate Prior Distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mcmc">18.6.1. MCMC</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vi-with-a-truncated-normal-guide">18.6.1.1. VI with a  Truncated Normal Guide</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#variational-inference-with-a-beta-guide-distribution">18.6.1.2. Variational Inference with a  Beta Guide Distribution</a></li>
</ul>
</li>
</ul>
</li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="_static/qe-logo-large.png" class="logo logo-img" alt="logo"></a>
                                    
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="intro.html">Intermediate Quantitative Economics with Python</a></p>

                        <p class="qe-page__header-subheading">Non-Conjugate Priors</p>

                    </div>
                    <!-- length 2, since its a string and empty dict has length 2 - {} -->
                        <p class="qe-page__header-authors" font-size="18">
                            
                                
                                    <a href="http://www.tomsargent.com/" target="_blank"><span>Thomas J. Sargent</span></a>
                                
                            
                                
                                    and <a href="https://johnstachurski.net/" target="_blank"><span>John Stachurski</span></a>
                                
                            
                        </p>


                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <section class="tex2jax_ignore mathjax_ignore" id="non-conjugate-priors">
<h1><span class="section-number">18. </span>Non-Conjugate Priors<a class="headerlink" href="#non-conjugate-priors" title="Permalink to this heading">#</a></h1>
<div class="warning admonition">
<p class="admonition-title">GPU</p>
<p>This lecture was built using a machine with the latest CUDA and CUDANN frameworks installed with access to a GPU.</p>
<p>To run this lecture on <a class="reference external" href="https://colab.research.google.com/">Google Colab</a>, click on the “play” icon top right, select Colab, and set the runtime environment to include a GPU.</p>
<p>To run this lecture on your own machine, you need to install the software listed following this notice.</p>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>numpyro<span class="w"> </span>pyro-ppl<span class="w"> </span>torch<span class="w"> </span>jax
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: numpyro in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (0.19.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting pyro-ppl
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: torch in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (2.9.0.dev20250824+cu128)
Requirement already satisfied: jax in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (0.6.2)
Requirement already satisfied: jaxlib&gt;=0.4.25 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from numpyro) (0.6.2)
Requirement already satisfied: multipledispatch in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from numpyro) (0.6.0)
Requirement already satisfied: numpy in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from numpyro) (1.26.4)
Requirement already satisfied: tqdm in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from numpyro) (4.66.5)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from pyro-ppl) (3.4.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting pyro-api&gt;=0.1.1 (from pyro-ppl)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)
Requirement already satisfied: filelock in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (3.19.1)
Requirement already satisfied: typing-extensions&gt;=4.10.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (4.11.0)
Requirement already satisfied: setuptools in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (75.1.0)
Requirement already satisfied: sympy&gt;=1.13.3 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (1.14.0)
Requirement already satisfied: networkx&gt;=2.5.1 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (3.3)
Requirement already satisfied: jinja2 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (3.1.4)
Requirement already satisfied: fsspec&gt;=0.8.5 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (2024.6.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (9.10.2.21)
Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (12.8.4.1)
Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (11.3.3.83)
Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (10.3.9.90)
Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (11.7.3.90)
Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (12.5.8.93)
Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (0.7.1)
Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (2.27.5)
Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (3.3.20)
Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (12.8.90)
Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (12.8.93)
Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (1.13.1.3)
Requirement already satisfied: pytorch-triton==3.4.0+gitf7888497 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from torch) (3.4.0+gitf7888497)
Requirement already satisfied: ml_dtypes&gt;=0.5.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from jax) (0.5.3)
Requirement already satisfied: scipy&gt;=1.12 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from jax) (1.13.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from sympy&gt;=1.13.3-&gt;torch) (1.3.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from jinja2-&gt;torch) (2.1.3)
Requirement already satisfied: six in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from multipledispatch-&gt;numpyro) (1.16.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)
?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">0.0/756.0 kB</span> <span class=" -Color -Color-Red">?</span> eta <span class=" -Color -Color-Cyan">-:--:--</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class=" -Color -Color-Green">756.0/756.0 kB</span> <span class=" -Color -Color-Red">23.1 MB/s</span> eta <span class=" -Color -Color-Cyan">0:00:00</span>
?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Installing collected packages: pyro-api, pyro-ppl
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Successfully installed pyro-api-0.1.2 pyro-ppl-1.9.1
</pre></div>
</div>
</div>
</details>
</div>
<p>This lecture is a sequel to the <a class="reference internal" href="prob_meaning.html"><span class="doc">quantecon lecture</span></a>.</p>
<p>That lecture offers a Bayesian interpretation of probability in a setting in which the likelihood function and the prior distribution
over parameters just happened to form a <strong>conjugate</strong> pair in which</p>
<ul class="simple">
<li><p>application of Bayes’ Law produces a posterior distribution that has the same functional form as the prior</p></li>
</ul>
<p>Having a likelihood and prior that  are conjugate can simplify calculation of a posterior, faciltating  analytical or nearly analytical calculations.</p>
<p>But in many situations  the likelihood and prior need not form a conjugate pair.</p>
<ul class="simple">
<li><p>after all, a person’s prior is his or her own business and would take a form conjugate to a likelihood only by remote coincidence</p></li>
</ul>
<p>In these situations, computing a posterior can become very challenging.</p>
<p>In this lecture, we illustrate how modern Bayesians confront non-conjugate priors  by using  Monte Carlo techniques that involve</p>
<ul class="simple">
<li><p>first  cleverly forming a Markov chain whose invariant distribution is the posterior distribution we want</p></li>
<li><p>simulating the Markov chain until it has converged and then sampling from the invariant distribution to approximate the posterior</p></li>
</ul>
<p>We shall illustrate the approach by deploying two powerful Python modules that implement this approach as well as another closely related one to
be described below.</p>
<p>The two Python modules are</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">numpyro</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pymc4</span></code></p></li>
</ul>
<p>As usual, we begin by importing some Python code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">lax</span><span class="p">,</span> <span class="n">random</span>

<span class="c1"># pyro</span>
<span class="kn">import</span> <span class="nn">pyro</span>
<span class="kn">from</span> <span class="nn">pyro</span> <span class="kn">import</span> <span class="n">distributions</span> <span class="k">as</span> <span class="n">dist</span>
<span class="kn">import</span> <span class="nn">pyro.distributions.constraints</span> <span class="k">as</span> <span class="nn">constraints</span>
<span class="kn">from</span> <span class="nn">pyro.infer</span> <span class="kn">import</span> <span class="n">MCMC</span><span class="p">,</span> <span class="n">NUTS</span><span class="p">,</span> <span class="n">SVI</span><span class="p">,</span> <span class="n">ELBO</span><span class="p">,</span> <span class="n">Trace_ELBO</span>
<span class="kn">from</span> <span class="nn">pyro.optim</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="c1"># numpyro</span>
<span class="kn">import</span> <span class="nn">numpyro</span>
<span class="kn">from</span> <span class="nn">numpyro</span> <span class="kn">import</span> <span class="n">distributions</span> <span class="k">as</span> <span class="n">ndist</span>
<span class="kn">import</span> <span class="nn">numpyro.distributions.constraints</span> <span class="k">as</span> <span class="nn">nconstraints</span>
<span class="kn">from</span> <span class="nn">numpyro.infer</span> <span class="kn">import</span> <span class="n">MCMC</span> <span class="k">as</span> <span class="n">nMCMC</span>
<span class="kn">from</span> <span class="nn">numpyro.infer</span> <span class="kn">import</span> <span class="n">NUTS</span> <span class="k">as</span> <span class="n">nNUTS</span>
<span class="kn">from</span> <span class="nn">numpyro.infer</span> <span class="kn">import</span> <span class="n">SVI</span> <span class="k">as</span> <span class="n">nSVI</span>
<span class="kn">from</span> <span class="nn">numpyro.infer</span> <span class="kn">import</span> <span class="n">ELBO</span> <span class="k">as</span> <span class="n">nELBO</span>
<span class="kn">from</span> <span class="nn">numpyro.infer</span> <span class="kn">import</span> <span class="n">Trace_ELBO</span> <span class="k">as</span> <span class="n">nTrace_ELBO</span>
<span class="kn">from</span> <span class="nn">numpyro.optim</span> <span class="kn">import</span> <span class="n">Adam</span> <span class="k">as</span> <span class="n">nAdam</span>
</pre></div>
</div>
</div>
</div>
<section id="unleashing-mcmc-on-a-binomial-likelihood">
<h2><span class="section-number">18.1. </span>Unleashing MCMC on a  Binomial Likelihood<a class="headerlink" href="#unleashing-mcmc-on-a-binomial-likelihood" title="Permalink to this heading">#</a></h2>
<p>This lecture begins with the binomial example in the <a class="reference internal" href="prob_meaning.html"><span class="doc">quantecon lecture</span></a>.</p>
<p>That lecture computed a posterior</p>
<ul class="simple">
<li><p>analytically via choosing the conjugate priors,</p></li>
</ul>
<p>This lecture instead computes posteriors</p>
<ul class="simple">
<li><p>numerically by sampling from the posterior distribution through MCMC methods, and</p></li>
<li><p>using a variational inference (VI) approximation.</p></li>
</ul>
<p>We use both the packages <code class="docutils literal notranslate"><span class="pre">pyro</span></code> and <code class="docutils literal notranslate"><span class="pre">numpyro</span></code> with assistance from  <code class="docutils literal notranslate"><span class="pre">jax</span></code> to approximate a  posterior distribution</p>
<p>We use several alternative prior distributions</p>
<p>We  compare computed posteriors  with ones associated with a conjugate prior as described in  <a class="reference internal" href="prob_meaning.html"><span class="doc">the quantecon lecture</span></a></p>
<section id="analytical-posterior">
<h3><span class="section-number">18.1.1. </span>Analytical Posterior<a class="headerlink" href="#analytical-posterior" title="Permalink to this heading">#</a></h3>
<p>Assume that the random variable <span class="math notranslate nohighlight">\(X\sim Binom\left(n,\theta\right)\)</span>.</p>
<p>This defines a likelihood function</p>
<div class="math notranslate nohighlight">
\[
L\left(Y\vert\theta\right) = \textrm{Prob}(X =  k | \theta) =
\left(\frac{n!}{k! (n-k)!} \right) \theta^k (1-\theta)^{n-k}
\]</div>
<p>where <span class="math notranslate nohighlight">\(Y=k\)</span> is an observed data point.</p>
<p>We view  <span class="math notranslate nohighlight">\(\theta\)</span> as a random variable for which we assign a prior distribution having density <span class="math notranslate nohighlight">\(f(\theta)\)</span>.</p>
<p>We will try alternative priors later, but for now, suppose the prior is distributed as <span class="math notranslate nohighlight">\(\theta\sim Beta\left(\alpha,\beta\right)\)</span>, i.e.,</p>
<div class="math notranslate nohighlight">
\[
f(\theta) = \textrm{Prob}(\theta) = \frac{\theta^{\alpha - 1} (1 - \theta)^{\beta - 1}}{B(\alpha, \beta)}
\]</div>
<p>We choose this as our prior for now because  we know that a conjugate prior for the binomial likelihood function is a beta distribution.</p>
<p>After observing  <span class="math notranslate nohighlight">\(k\)</span> successes among <span class="math notranslate nohighlight">\(N\)</span> sample observations, the posterior  probability distributionof  <span class="math notranslate nohighlight">\( \theta \)</span> is</p>
<div class="math notranslate nohighlight">
\[
\textrm{Prob}(\theta|k) = \frac{\textrm{Prob}(\theta,k)}{\textrm{Prob}(k)}=\frac{\textrm{Prob}(k|\theta)\textrm{Prob}(\theta)}{\textrm{Prob}(k)}=\frac{\textrm{Prob}(k|\theta) \textrm{Prob}(\theta)}{\int_0^1 \textrm{Prob}(k|\theta)\textrm{Prob}(\theta) d\theta}
\]</div>
<div class="math notranslate nohighlight">
\[
=\frac{{N \choose k} (1 - \theta)^{N-k} \theta^k \frac{\theta^{\alpha - 1} (1 - \theta)^{\beta - 1}}{B(\alpha, \beta)}}{\int_0^1 {N \choose k} (1 - \theta)^{N-k} \theta^k\frac{\theta^{\alpha - 1} (1 - \theta)^{\beta - 1}}{B(\alpha, \beta)} d\theta}
\]</div>
<div class="math notranslate nohighlight">
\[
=\frac{(1 -\theta)^{\beta+N-k-1} \theta^{\alpha+k-1}}{\int_0^1 (1 - \theta)^{\beta+N-k-1} \theta^{\alpha+k-1} d\theta} .
\]</div>
<p>Thus,</p>
<div class="math notranslate nohighlight">
\[
\textrm{Prob}(\theta|k) \sim {Beta}(\alpha + k, \beta+N-k)
\]</div>
<p>The analytical posterior for a given conjugate beta prior is coded in the following Python code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_draw</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draws a Bernoulli sample of size n with probability P(Y=1) = theta</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rand_draw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="n">draw</span> <span class="o">=</span> <span class="p">(</span><span class="n">rand_draw</span> <span class="o">&lt;</span> <span class="n">theta</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">draw</span>


<span class="k">def</span> <span class="nf">analytical_beta_posterior</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha0</span><span class="p">,</span> <span class="n">beta0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes analytically the posterior distribution with beta prior parametrized by (alpha, beta)</span>
<span class="sd">    given # num observations</span>

<span class="sd">    Parameters</span>
<span class="sd">    ---------</span>
<span class="sd">    num : int.</span>
<span class="sd">        the number of observations after which we calculate the posterior</span>
<span class="sd">    alpha0, beta0 : float.</span>
<span class="sd">        the parameters for the beta distribution as a prior</span>

<span class="sd">    Returns</span>
<span class="sd">    ---------</span>
<span class="sd">    The posterior beta distribution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">up_num</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">down_num</span> <span class="o">=</span> <span class="n">num</span> <span class="o">-</span> <span class="n">up_num</span>
    <span class="k">return</span> <span class="n">st</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">alpha0</span> <span class="o">+</span> <span class="n">up_num</span><span class="p">,</span> <span class="n">beta0</span> <span class="o">+</span> <span class="n">down_num</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="two-ways-to-approximate-posteriors">
<h3><span class="section-number">18.1.2. </span>Two Ways to Approximate Posteriors<a class="headerlink" href="#two-ways-to-approximate-posteriors" title="Permalink to this heading">#</a></h3>
<p>Suppose that we don’t have a conjugate prior.</p>
<p>Then  we  can’t compute posteriors analytically.</p>
<p>Instead,  we use computational tools to approximate the posterior distribution for a set of alternative prior distributions using both <code class="docutils literal notranslate"><span class="pre">Pyro</span></code> and <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code> packages in Python.</p>
<p>We first use the <strong>Markov Chain Monte Carlo</strong> (MCMC) algorithm .</p>
<p>We implement the NUTS sampler to sample from the posterior.</p>
<p>In that way we construct a sampling distribution that approximates the  posterior.</p>
<p>After doing that we deply another procedure called  <strong>Variational Inference</strong> (VI).</p>
<p>In particular, we implement Stochastic Variational Inference (SVI) machinery in both <code class="docutils literal notranslate"><span class="pre">Pyro</span></code> and <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code>.</p>
<p>The MCMC algorithm  supposedly generates a more accurate approximation since in principle it directly samples from the posterior distribution.</p>
<p>But it  can be computationally expensive, especially when dimension is large.</p>
<p>A VI approach can be  cheaper, but it is likely to produce an inferior approximation to the posterior, for the simple reason that it requires guessing a parametric <strong>guide functional form</strong> that we use to approximate a posterior.</p>
<p>This guide function is likely  at best to be an imperfect approximation.</p>
<p>By paying the cost of restricting the putative posterior to have a restricted functional form,
the problem of approximating a posteriors is transformed to a well-posed optimization problem that seeks parameters of the putative posterior  that minimize
a Kullback-Leibler (KL) divergence between true posterior and the putatitive posterior  distribution.</p>
<ul class="simple">
<li><p>minimizing the KL divergence is  equivalent with  maximizing a criterion called  the <strong>Evidence Lower Bound</strong> (ELBO), as we shall verify soon.</p></li>
</ul>
</section>
</section>
<section id="prior-distributions">
<h2><span class="section-number">18.2. </span>Prior Distributions<a class="headerlink" href="#prior-distributions" title="Permalink to this heading">#</a></h2>
<p>In order to be able to apply MCMC sampling or VI, <code class="docutils literal notranslate"><span class="pre">Pyro</span></code> and <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code> require  that a prior distribution satisfy special properties:</p>
<ul class="simple">
<li><p>we must be able sample from it;</p></li>
<li><p>we must be able to  compute the log pdf  pointwise;</p></li>
<li><p>the pdf must be  differentiable with respect to the parameters.</p></li>
</ul>
<p>We’ll want to define a distribution <code class="docutils literal notranslate"><span class="pre">class</span></code>.</p>
<p>We  will use the following priors:</p>
<ul class="simple">
<li><p>a uniform distribution on <span class="math notranslate nohighlight">\([\underline \theta, \overline \theta]\)</span>, where <span class="math notranslate nohighlight">\(0 \leq \underline \theta &lt; \overline \theta \leq 1\)</span>.</p></li>
<li><p>a truncated log-normal distribution with support on <span class="math notranslate nohighlight">\([0,1]\)</span> with parameters <span class="math notranslate nohighlight">\((\mu,\sigma)\)</span>.</p>
<ul>
<li><p>To implement this, let <span class="math notranslate nohighlight">\(Z\sim Normal(\mu,\sigma)\)</span> and <span class="math notranslate nohighlight">\(\tilde{Z}\)</span> be truncated normal with support <span class="math notranslate nohighlight">\([\log(0),\log(1)]\)</span>, then <span class="math notranslate nohighlight">\(\exp(Z)\)</span> has a log normal distribution with bounded support <span class="math notranslate nohighlight">\([0,1]\)</span>. This can be easily coded since <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code> has a built-in truncated normal distribution, and <code class="docutils literal notranslate"><span class="pre">Torch</span></code> provides a <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> class that includes an exponential transformation.</p></li>
<li><p>Alternatively, we can use a rejection sampling strategy by assigning the probability rate to <span class="math notranslate nohighlight">\(0\)</span> outside the bounds and rescaling accepted samples, i.e., realizations that are within the bounds, by the total probability computed via CDF of the original distribution. This can be implemented by defining a truncated distribution class with <code class="docutils literal notranslate"><span class="pre">pyro</span></code>’s <code class="docutils literal notranslate"><span class="pre">dist.Rejector</span></code> class.</p></li>
<li><p>We implement both methods in the below section and verify that they  produce the same result.</p></li>
</ul>
</li>
<li><p>a shifted von Mises distribution that has support confined to <span class="math notranslate nohighlight">\([0,1]\)</span> with parameter <span class="math notranslate nohighlight">\((\mu,\kappa)\)</span>.</p>
<ul>
<li><p>Let <span class="math notranslate nohighlight">\(X\sim vonMises(0,\kappa)\)</span>. We know that <span class="math notranslate nohighlight">\(X\)</span> has bounded support <span class="math notranslate nohighlight">\([-\pi, \pi]\)</span>. We can define a shifted von Mises random variable <span class="math notranslate nohighlight">\(\tilde{X}=a+bX\)</span> where <span class="math notranslate nohighlight">\(a=0.5, b=1/(2 \pi)\)</span> so that <span class="math notranslate nohighlight">\(\tilde{X}\)</span> is supported on <span class="math notranslate nohighlight">\([0,1]\)</span>.</p></li>
<li><p>This can be implemented using <code class="docutils literal notranslate"><span class="pre">Torch</span></code>’s <code class="docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> class  with its <code class="docutils literal notranslate"><span class="pre">AffineTransform</span></code> method.</p></li>
<li><p>If instead, we want the prior to be von-Mises distributed with center <span class="math notranslate nohighlight">\(\mu=0.5\)</span>, we can choose a high concentration level <span class="math notranslate nohighlight">\(\kappa\)</span> so that most mass is located between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>. Then we can truncate the distribution using the above strategy. This can be implemented using  <code class="docutils literal notranslate"><span class="pre">pyro</span></code>’s <code class="docutils literal notranslate"><span class="pre">dist.Rejector</span></code> class. We choose <span class="math notranslate nohighlight">\(\kappa &gt; 40\)</span> in this case.</p></li>
</ul>
</li>
<li><p>a truncated Laplace distribution.</p>
<ul>
<li><p>We also considered a truncated Laplace distribution because its density comes in a piece-wise non-smooth form and has a distinctive spiked shape.</p></li>
<li><p>The truncated Laplace can be created using <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code>’s <code class="docutils literal notranslate"><span class="pre">TruncatedDistribution</span></code> class.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># used by Numpyro</span>
<span class="k">def</span> <span class="nf">TruncatedLogNormal_trans</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Obtains the truncated log normal distribution using numpyro&#39;s TruncatedNormal and ExpTransform</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base_dist</span> <span class="o">=</span> <span class="n">ndist</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">high</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ndist</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span>
        <span class="n">base_dist</span><span class="p">,</span><span class="n">ndist</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ExpTransform</span><span class="p">()</span>
        <span class="p">)</span>

<span class="k">def</span> <span class="nf">ShiftedVonMises</span><span class="p">(</span><span class="n">kappa</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Obtains the shifted von Mises distribution using AffineTransform</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base_dist</span> <span class="o">=</span> <span class="n">ndist</span><span class="o">.</span><span class="n">VonMises</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">kappa</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ndist</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span>
        <span class="n">base_dist</span><span class="p">,</span> <span class="n">ndist</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">AffineTransform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">jnp</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
        <span class="p">)</span>

<span class="k">def</span> <span class="nf">TruncatedLaplace</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Obtains the truncated Laplace distribution on [0,1]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">base_dist</span> <span class="o">=</span> <span class="n">ndist</span><span class="o">.</span><span class="n">Laplace</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ndist</span><span class="o">.</span><span class="n">TruncatedDistribution</span><span class="p">(</span>
        <span class="n">base_dist</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span>
    <span class="p">)</span>

<span class="c1"># used by Pyro</span>
<span class="k">class</span> <span class="nc">TruncatedLogNormal</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Rejector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a TruncatedLogNormal distribution through rejection sampling in Pyro</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">scale_0</span><span class="p">,</span> <span class="n">upp</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">upp</span> <span class="o">=</span> <span class="n">upp</span>
        <span class="n">propose</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_0</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">log_prob_accept</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">upp</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>

        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">LogNormal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_0</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">upp</span><span class="p">))</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TruncatedLogNormal</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">propose</span><span class="p">,</span> <span class="n">log_prob_accept</span><span class="p">,</span> <span class="n">log_scale</span><span class="p">)</span>

    <span class="nd">@constraints</span><span class="o">.</span><span class="n">dependent_property</span>
    <span class="k">def</span> <span class="nf">support</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">constraints</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">upp</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TruncatedvonMises</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">Rejector</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Define a TruncatedvonMises distribution through rejection sampling in Pyro</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kappa</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">upp</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">upp</span> <span class="o">=</span> <span class="n">low</span><span class="p">,</span> <span class="n">upp</span>
        <span class="n">propose</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">VonMises</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">kappa</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">log_prob_accept</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="p">((</span><span class="n">x</span> <span class="o">&gt;</span> <span class="n">low</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">upp</span><span class="p">))</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>

        <span class="n">log_scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
                <span class="n">st</span><span class="o">.</span><span class="n">vonmises</span><span class="p">(</span><span class="n">kappa</span><span class="o">=</span><span class="n">kappa</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">upp</span><span class="p">)</span>
                <span class="o">-</span> <span class="n">st</span><span class="o">.</span><span class="n">vonmises</span><span class="p">(</span><span class="n">kappa</span><span class="o">=</span><span class="n">kappa</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">low</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TruncatedvonMises</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">propose</span><span class="p">,</span> <span class="n">log_prob_accept</span><span class="p">,</span> <span class="n">log_scale</span><span class="p">)</span>

    <span class="nd">@constraints</span><span class="o">.</span><span class="n">dependent_property</span>
    <span class="k">def</span> <span class="nf">support</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">constraints</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">low</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">upp</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="variational-inference">
<h3><span class="section-number">18.2.1. </span>Variational Inference<a class="headerlink" href="#variational-inference" title="Permalink to this heading">#</a></h3>
<p>Instead of directly sampling from the posterior,  the <strong>variational inference</strong>  methodw approximates an unknown posterior distribution with  a family of tractable distributions/densities.</p>
<p>It then seeks to minimizes a measure of statistical discrepancy between the approximating and  true posteriors.</p>
<p>Thus variational inference (VI)  approximates a posterior by solving  a  minimization problem.</p>
<p>Let the latent parameter/variable that we want to infer  be <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Let the  prior be  <span class="math notranslate nohighlight">\(p(\theta)\)</span> and the likelihood be <span class="math notranslate nohighlight">\(p\left(Y\vert\theta\right)\)</span>.</p>
<p>We want  <span class="math notranslate nohighlight">\(p\left(\theta\vert Y\right)\)</span>.</p>
<p>Bayes’ rule implies</p>
<div class="math notranslate nohighlight">
\[
p\left(\theta\vert Y\right)=\frac{p\left(Y,\theta\right)}{p\left(Y\right)}=\frac{p\left(Y\vert\theta\right)p\left(\theta\right)}{p\left(Y\right)}
\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-eq-intchallenge">
<span class="eqno">(18.1)<a class="headerlink" href="#equation-eq-intchallenge" title="Permalink to this equation">#</a></span>\[
p\left(Y\right)=\int d\theta p\left(Y\mid\theta\right)p\left(Y\right).
\]</div>
<p>The integral on the right side of <a class="reference internal" href="#equation-eq-intchallenge">(18.1)</a>  is typically difficult to compute.</p>
<p>Consider a  <strong>guide distribution</strong> <span class="math notranslate nohighlight">\(q_{\phi}(\theta)\)</span> parameterized by <span class="math notranslate nohighlight">\(\phi\)</span> that we’ll use to approximate the posterior.</p>
<p>We choose  parameters <span class="math notranslate nohighlight">\(\phi\)</span> of the guide distribution to minimize a Kullback-Leibler (KL)  divergence between the approximate posterior <span class="math notranslate nohighlight">\(q_{\phi}(\theta)\)</span> and  the posterior:</p>
<div class="math notranslate nohighlight">
\[
 D_{KL}(q(\theta;\phi)\;\|\;p(\theta\mid Y)) \equiv -\int d\theta q(\theta;\phi)\log\frac{p(\theta\mid Y)}{q(\theta;\phi)}
\]</div>
<p>Thus, we want a <strong>variational distribution</strong> <span class="math notranslate nohighlight">\(q\)</span> that solves</p>
<div class="math notranslate nohighlight">
\[
\min_{\phi}\quad D_{KL}(q(\theta;\phi)\;\|\;p(\theta\mid Y))
\]</div>
<p>Note that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}D_{KL}(q(\theta;\phi)\;\|\;p(\theta\mid Y)) &amp; =-\int d\theta q(\theta;\phi)\log\frac{P(\theta\mid Y)}{q(\theta;\phi)}\\
 &amp; =-\int d\theta q(\theta)\log\frac{\frac{p(\theta,Y)}{p(Y)}}{q(\theta)}\\
 &amp; =-\int d\theta q(\theta)\log\frac{p(\theta,Y)}{p(\theta)q(Y)}\\
 &amp; =-\int d\theta q(\theta)\left[\log\frac{p(\theta,Y)}{q(\theta)}-\log p(Y)\right]\\
 &amp; =-\int d\theta q(\theta)\log\frac{p(\theta,Y)}{q(\theta)}+\int d\theta q(\theta)\log p(Y)\\
 &amp; =-\int d\theta q(\theta)\log\frac{p(\theta,Y)}{q(\theta)}+\log p(Y)\\
\log p(Y)&amp;=D_{KL}(q(\theta;\phi)\;\|\;p(\theta\mid Y))+\int d\theta q_{\phi}(\theta)\log\frac{p(\theta,Y)}{q_{\phi}(\theta)}
\end{aligned}
\end{split}\]</div>
<p>For  observed data <span class="math notranslate nohighlight">\(Y\)</span>, <span class="math notranslate nohighlight">\(p(\theta,Y)\)</span> is a constant, so minimizing KL divergence is equivalent to maximizing</p>
<div class="math notranslate nohighlight" id="equation-eq-elbo">
<span class="eqno">(18.2)<a class="headerlink" href="#equation-eq-elbo" title="Permalink to this equation">#</a></span>\[
ELBO\equiv\int d\theta q_{\phi}(\theta)\log\frac{p(\theta,Y)}{q_{\phi}(\theta)}=\mathbb{E}_{q_{\phi}(\theta)}\left[\log p(\theta,Y)-\log q_{\phi}(\theta)\right]
\]</div>
<p>Formula <a class="reference internal" href="#equation-eq-elbo">(18.2)</a> is called  the evidence lower bound (ELBO).</p>
<p>A standard optimization routine can used to search for the optimal <span class="math notranslate nohighlight">\(\phi\)</span> in our parametrized distribution <span class="math notranslate nohighlight">\(q_{\phi}(\theta)\)</span>.</p>
<p>The parameterized  distribution <span class="math notranslate nohighlight">\(q_{\phi}(\theta)\)</span> is called the <strong>variational distribution</strong>.</p>
<p>We can implement Stochastic Variational Inference (SVI) in Pyro and Numpyro using the <code class="docutils literal notranslate"><span class="pre">Adam</span></code> gradient descent algorithm to approximate posterior.</p>
<p>We use  two sets of variational distributions: Beta and TruncatedNormal with support <span class="math notranslate nohighlight">\([0,1]\)</span></p>
<ul class="simple">
<li><p>Learnable parameters for the Beta distribution are (alpha, beta), both of which are positive.</p></li>
<li><p>Learnable parameters for the Truncated Normal distribution are (loc, scale).</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We restrict the truncated Normal parameter ‘loc’ to be in the interval <span class="math notranslate nohighlight">\([0,1]\)</span></p>
</div>
</section>
</section>
<section id="implementation">
<h2><span class="section-number">18.3. </span>Implementation<a class="headerlink" href="#implementation" title="Permalink to this heading">#</a></h2>
<p>We have constructed a Python class <code class="docutils literal notranslate"><span class="pre">BaysianInference</span></code> that requires the following arguments to be initialized:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">param</span></code>: a tuple/scalar of parameters dependent on distribution types</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name_dist</span></code>: a string that specifies distribution names</p></li>
</ul>
<p>The (<code class="docutils literal notranslate"><span class="pre">param</span></code>, <code class="docutils literal notranslate"><span class="pre">name_dist</span></code>) pair includes:</p>
<ul class="simple">
<li><p>(‘beta’, alpha, beta)</p></li>
<li><p>(‘uniform’, upper_bound, lower_bound)</p></li>
<li><p>(‘lognormal’, loc, scale)</p>
<ul>
<li><p>Note: This is the truncated log normal.</p></li>
</ul>
</li>
<li><p>(‘vonMises’, kappa), where kappa denotes concentration parameter, and center location is set to <span class="math notranslate nohighlight">\(0.5\)</span>.</p>
<ul>
<li><p>Note: When using <code class="docutils literal notranslate"><span class="pre">Pyro</span></code>, this is the truncated version of the original vonMises distribution;</p></li>
<li><p>Note: When using <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code>, this is the <strong>shifted</strong> distribution.</p></li>
</ul>
</li>
<li><p>(‘laplace’, loc, scale)</p>
<ul>
<li><p>Note: This is the truncated Laplace</p></li>
</ul>
</li>
</ul>
<p>The class <code class="docutils literal notranslate"><span class="pre">BaysianInference</span></code> has several key methods :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sample_prior</span></code>:</p>
<ul>
<li><p>This can be used to draw a single sample from the given prior distribution.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">show_prior</span></code>:</p>
<ul>
<li><p>Plots the approximate prior distribution by repeatedly drawing samples and fitting a kernal density curve.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">MCMC_sampling</span></code>:</p>
<ul>
<li><p>INPUT: (data, num_samples, num_warmup=1000)</p></li>
<li><p>Take a <code class="docutils literal notranslate"><span class="pre">np.array</span></code> data and generate MCMC sampling of posterior of size <code class="docutils literal notranslate"><span class="pre">num_samples</span></code>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">SVI_run</span></code>:</p>
<ul>
<li><p>INPUT: (data, guide_dist, n_steps=10000)</p></li>
<li><p>guide_dist = ‘normal’ - use a <strong>truncated</strong> normal distribution as the parametrized guide</p></li>
<li><p>guide_dist = ‘beta’ - use a beta distribution as the parametrized guide</p></li>
<li><p>RETURN: (params, losses) - the learned parameters in a <code class="docutils literal notranslate"><span class="pre">dict</span></code> and the vector of loss at each step.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BayesianInference</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">name_dist</span><span class="p">,</span> <span class="n">solver</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ---------</span>
<span class="sd">        param : tuple.</span>
<span class="sd">            a tuple object that contains all relevant parameters for the distribution</span>
<span class="sd">        dist : str.</span>
<span class="sd">            name of the distribution - &#39;beta&#39;, &#39;uniform&#39;, &#39;lognormal&#39;, &#39;vonMises&#39;, &#39;tent&#39;</span>
<span class="sd">        solver : str.</span>
<span class="sd">            either pyro or numpyro</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">param</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name_dist</span> <span class="o">=</span> <span class="n">name_dist</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">=</span> <span class="n">solver</span>

        <span class="c1"># jax requires explicit PRNG state to be passed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rng_key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">sample_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Define the prior distribution to sample from in Pyro/Numpyro models.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_dist</span><span class="o">==</span><span class="s1">&#39;beta&#39;</span><span class="p">:</span>
            <span class="c1"># unpack parameters</span>
            <span class="n">alpha0</span><span class="p">,</span> <span class="n">beta0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="n">alpha0</span><span class="p">,</span> <span class="n">beta0</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">ndist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="n">alpha0</span><span class="p">,</span> <span class="n">beta0</span><span class="p">),</span> <span class="n">rng_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng_key</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_dist</span><span class="o">==</span><span class="s1">&#39;uniform&#39;</span><span class="p">:</span>
            <span class="c1"># unpack parameters</span>
            <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">ndist</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">),</span> <span class="n">rng_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng_key</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_dist</span><span class="o">==</span><span class="s1">&#39;lognormal&#39;</span><span class="p">:</span>
            <span class="c1"># unpack parameters</span>
            <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">TruncatedLogNormal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">TruncatedLogNormal_trans</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">),</span> <span class="n">rng_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng_key</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_dist</span><span class="o">==</span><span class="s1">&#39;vonMises&#39;</span><span class="p">:</span>
            <span class="c1"># unpack parameters</span>
            <span class="n">kappa</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">TruncatedvonMises</span><span class="p">(</span><span class="n">kappa</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">ShiftedVonMises</span><span class="p">(</span><span class="n">kappa</span><span class="p">),</span> <span class="n">rng_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng_key</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_dist</span><span class="o">==</span><span class="s1">&#39;laplace&#39;</span><span class="p">:</span>
            <span class="c1"># unpack parameters</span>
            <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: Please use Numpyro for truncated Laplace.&quot;</span><span class="p">)</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">TruncatedLaplace</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">),</span> <span class="n">rng_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rng_key</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sample</span>


    <span class="k">def</span> <span class="nf">show_prior</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">disp_plot</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Visualizes prior distribution by sampling from prior and plots the approximated sampling distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bins</span> <span class="o">=</span> <span class="n">bins</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">pyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s1">&#39;show_prior&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">):</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_prior</span><span class="p">()</span>
            <span class="c1"># to numpy</span>
            <span class="n">sample_array</span> <span class="o">=</span> <span class="n">sample</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;numpyro&#39;</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">plate</span><span class="p">(</span><span class="s1">&#39;show_prior&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">):</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_prior</span><span class="p">()</span>
            <span class="c1"># to numpy</span>
            <span class="n">sample_array</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

        <span class="c1"># plot histogram and kernel density</span>
        <span class="k">if</span> <span class="n">disp_plot</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
            <span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">sample_array</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">sample_array</span>


    <span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Define the probabilistic model by specifying prior, conditional likelihood, and data conditioning</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="c1"># set prior</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_prior</span><span class="p">()</span>

        <span class="c1"># sample from conditional likelihood</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;obs&#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">theta</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Note: numpyro.sample() requires obs=np.ndarray</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;obs&#39;</span><span class="p">,</span> <span class="n">ndist</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">theta</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">output</span>


    <span class="k">def</span> <span class="nf">MCMC_sampling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_warmup</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes numerically the posterior distribution with beta prior parametrized by (alpha0, beta0)</span>
<span class="sd">        given data using MCMC</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># use pyro</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
            <span class="c1"># tensorize</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">nuts_kernel</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
            <span class="n">mcmc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">nuts_kernel</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="o">=</span><span class="n">num_warmup</span><span class="p">,</span> <span class="n">disable_progbar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">mcmc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># use numpyro</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;numpyro&#39;</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="n">nuts_kernel</span> <span class="o">=</span> <span class="n">nNUTS</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
            <span class="n">mcmc</span> <span class="o">=</span> <span class="n">nMCMC</span><span class="p">(</span><span class="n">nuts_kernel</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span> <span class="n">num_warmup</span><span class="o">=</span><span class="n">num_warmup</span><span class="p">,</span> <span class="n">progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">mcmc</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># collect samples</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">mcmc</span><span class="o">.</span><span class="n">get_samples</span><span class="p">()[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">samples</span>


    <span class="k">def</span> <span class="nf">beta_guide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Defines the candidate parametrized variational distribution that we train to approximate posterior with Pyro/Numpyro</span>
<span class="sd">        Here we use parameterized beta</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
            <span class="n">alpha_q</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;alpha_q&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
                            <span class="n">constraint</span><span class="o">=</span><span class="n">constraints</span><span class="o">.</span><span class="n">positive</span><span class="p">)</span>
            <span class="n">beta_q</span> <span class="o">=</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;beta_q&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span>
                            <span class="n">constraint</span><span class="o">=</span><span class="n">constraints</span><span class="o">.</span><span class="n">positive</span><span class="p">)</span>
            <span class="n">pyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="n">alpha_q</span><span class="p">,</span> <span class="n">beta_q</span><span class="p">))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">alpha_q</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;alpha_q&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
                            <span class="n">constraint</span><span class="o">=</span><span class="n">nconstraints</span><span class="o">.</span><span class="n">positive</span><span class="p">)</span>
            <span class="n">beta_q</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;beta_q&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span>
                            <span class="n">constraint</span><span class="o">=</span><span class="n">nconstraints</span><span class="o">.</span><span class="n">positive</span><span class="p">)</span>

            <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">ndist</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="n">alpha_q</span><span class="p">,</span> <span class="n">beta_q</span><span class="p">))</span>


    <span class="k">def</span> <span class="nf">truncnormal_guide</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Defines the candidate parametrized variational distribution that we train to approximate posterior with Pyro/Numpyro</span>
<span class="sd">        Here we use truncated normal on [0,1]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">loc</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;loc&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span>
                        <span class="n">constraint</span><span class="o">=</span><span class="n">nconstraints</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">numpyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">constraint</span><span class="o">=</span><span class="n">nconstraints</span><span class="o">.</span><span class="n">positive</span><span class="p">)</span>
        <span class="n">numpyro</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="n">ndist</span><span class="o">.</span><span class="n">TruncatedNormal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>


    <span class="k">def</span> <span class="nf">SVI_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">guide_dist</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initiate SVI training mode with Adam optimizer</span>
<span class="sd">        NOTE: truncnormal_guide can only be used with numpyro solver</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">adam_params</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">lr</span><span class="p">}</span>

        <span class="k">if</span> <span class="n">guide_dist</span><span class="o">==</span><span class="s1">&#39;beta&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">adam_params</span><span class="p">)</span>
                <span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;numpyro&#39;</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">nAdam</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
                <span class="n">svi</span> <span class="o">=</span> <span class="n">nSVI</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">nTrace_ELBO</span><span class="p">())</span>

        <span class="k">elif</span> <span class="n">guide_dist</span><span class="o">==</span><span class="s1">&#39;normal&#39;</span><span class="p">:</span>
            <span class="c1"># only allow numpyro</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: Please use Numpyro with TruncatedNormal guide&quot;</span><span class="p">)</span>
                <span class="n">svi</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;numpyro&#39;</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">nAdam</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
                <span class="n">svi</span> <span class="o">=</span> <span class="n">nSVI</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">truncnormal_guide</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">nTrace_ELBO</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WARNING: Please input either &#39;beta&#39; or &#39;normal&#39;&quot;</span><span class="p">)</span>
            <span class="n">svi</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="n">svi</span>

    <span class="k">def</span> <span class="nf">SVI_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">guide_dist</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs SVI and returns optimized parameters and losses</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        params : the learned parameters for guide</span>
<span class="sd">        losses : a vector of loss at each step</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># initiate SVI</span>
        <span class="n">svi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SVI_init</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="n">guide_dist</span><span class="p">)</span>

        <span class="c1"># do gradient steps</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;pyro&#39;</span><span class="p">:</span>
             <span class="c1"># tensorize data</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="c1"># store loss vector</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
                <span class="n">losses</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">svi</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

            <span class="c1"># pyro only supports beta VI distribution</span>
            <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;alpha_q&#39;</span><span class="p">:</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;alpha_q&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                <span class="s1">&#39;beta_q&#39;</span><span class="p">:</span> <span class="n">pyro</span><span class="o">.</span><span class="n">param</span><span class="p">(</span><span class="s1">&#39;beta_q&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="p">}</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="o">==</span><span class="s1">&#39;numpyro&#39;</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">svi</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rng_key</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">progress_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">value</span><span class="p">))</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="n">losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">losses</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="alternative-prior-distributions">
<h2><span class="section-number">18.4. </span>Alternative Prior Distributions<a class="headerlink" href="#alternative-prior-distributions" title="Permalink to this heading">#</a></h2>
<p>Let’s see how well our sampling algorithm does in approximating</p>
<ul class="simple">
<li><p>a log normal distribution</p></li>
<li><p>a uniform distribution</p></li>
</ul>
<p>To examine our alternative  prior distributions, we’ll plot  approximate prior distributions below by calling the <code class="docutils literal notranslate"><span class="pre">show_prior</span></code> method.</p>
<p>We verify that the rejection sampling strategy under <code class="docutils literal notranslate"><span class="pre">Pyro</span></code> produces the same log normal distribution as the truncated normal transformation under <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># truncated log normal</span>
<span class="n">exampleLN</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;lognormal&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>
<span class="n">exampleLN</span><span class="o">.</span><span class="n">show_prior</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># truncated uniform</span>
<span class="n">exampleUN</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.8</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>
<span class="n">exampleUN</span><span class="o">.</span><span class="n">show_prior</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b9c3b01d128108fdb6f54e4d9abb6a3b99aec07306c8c5a5c2c5a13ec749a96c.png" src="_images/b9c3b01d128108fdb6f54e4d9abb6a3b99aec07306c8c5a5c2c5a13ec749a96c.png" />
<img alt="_images/8959b1628e6f5ddde7029c4425f8ede06aefb1fa1cf163956b59e250d9c4942b.png" src="_images/8959b1628e6f5ddde7029c4425f8ede06aefb1fa1cf163956b59e250d9c4942b.png" />
</div>
</div>
<p>The above graphs show that sampling seems to work well with both distributions.</p>
<p>Now let’s see how well things work with a couple of von Mises distributions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># shifted von Mises</span>
<span class="n">exampleVM</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;vonMises&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>
<span class="n">exampleVM</span><span class="o">.</span><span class="n">show_prior</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># truncated von Mises</span>
<span class="n">exampleVM_trunc</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;vonMises&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;pyro&#39;</span><span class="p">)</span>
<span class="n">exampleVM_trunc</span><span class="o">.</span><span class="n">show_prior</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0cacfb27f9a674cd7068cb43f9260eb966d9967dffe2ecbca7d282d609373b5a.png" src="_images/0cacfb27f9a674cd7068cb43f9260eb966d9967dffe2ecbca7d282d609373b5a.png" />
<img alt="_images/ad44107151cc4126932de19874f0bcf5ac16acdc59645f312a1979c2ebec21d5.png" src="_images/ad44107151cc4126932de19874f0bcf5ac16acdc59645f312a1979c2ebec21d5.png" />
</div>
</div>
<p>These graphs look good too.</p>
<p>Now let’s try with a Laplace distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># truncated Laplace</span>
<span class="n">exampleLP</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;laplace&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>
<span class="n">exampleLP</span><span class="o">.</span><span class="n">show_prior</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/52e993490f436966f83c7e09bee0a627e9fbe6b9fb34169bd62a17db0e7e943f.png" src="_images/52e993490f436966f83c7e09bee0a627e9fbe6b9fb34169bd62a17db0e7e943f.png" />
</div>
</div>
<p>Having assured ourselves that our sampler seems to do a good job, let’s put it to work in using MCMC to compute posterior probabilities.</p>
</section>
<section id="posteriors-via-mcmc-and-vi">
<h2><span class="section-number">18.5. </span>Posteriors Via MCMC and VI<a class="headerlink" href="#posteriors-via-mcmc-and-vi" title="Permalink to this heading">#</a></h2>
<p>We construct a class  <code class="docutils literal notranslate"><span class="pre">BayesianInferencePlot</span></code> to implement MCMC or VI algorithms and plot multiple posteriors for different updating data sizes and different  possible prior.</p>
<p>This class takes as inputs the true data generating parameter ‘theta’, a list of updating data sizes for multiple posterior plotting, and a defined and parametrized <code class="docutils literal notranslate"><span class="pre">BayesianInference</span></code> class.</p>
<p>It has two key methods:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BayesianInferencePlot.MCMC_plot()</span></code> takes wanted MCMC sample size as input and plot the output posteriors  together with the prior defined in <code class="docutils literal notranslate"><span class="pre">BayesianInference</span></code> class.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BayesianInferencePlot.SVI_plot()</span></code> takes wanted VI distribution class (‘beta’ or ‘normal’) as input and plot the posteriors together with the prior.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BayesianInferencePlot</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Easily implement the MCMC and VI inference for a given instance of BayesianInference class and</span>
<span class="sd">    plot the prior together with multiple posteriors</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    theta : float.</span>
<span class="sd">        the true DGP parameter</span>
<span class="sd">    N_list : list.</span>
<span class="sd">        a list of sample size</span>
<span class="sd">    BayesianInferenceClass : class.</span>
<span class="sd">        a class initiated using BayesianInference()</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">N_list</span><span class="p">,</span> <span class="n">BayesianInferenceClass</span><span class="p">,</span> <span class="n">binwidth</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Enter Parameters for data generation and plotting</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_list</span> <span class="o">=</span> <span class="n">N_list</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">BayesianInferenceClass</span> <span class="o">=</span> <span class="n">BayesianInferenceClass</span>

        <span class="c1"># plotting parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">binwidth</span> <span class="o">=</span> <span class="n">binwidth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linewidth</span><span class="o">=</span><span class="mf">0.05</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">colorlist</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="n">n_colors</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">N_list</span><span class="p">))</span>

        <span class="c1"># data generation</span>
        <span class="n">N_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">N_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">simulate_draw</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">N_max</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">MCMC_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_warmup</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters as in MCMC_sampling except that data is already defined</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

        <span class="c1"># plot prior</span>
        <span class="n">prior_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">BayesianInferenceClass</span><span class="o">.</span><span class="n">show_prior</span><span class="p">(</span><span class="n">disp_plot</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">prior_sample</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span>
            <span class="n">binwidth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">binwidth</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#4C4E52&#39;</span><span class="p">,</span>
            <span class="n">linewidth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">linewidth</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Prior Distribution&#39;</span>
            <span class="p">)</span>

        <span class="c1"># plot posteriors</span>
        <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_list</span><span class="p">):</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">BayesianInferenceClass</span><span class="o">.</span><span class="n">MCMC_sampling</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">num_warmup</span>
            <span class="p">)</span>
            <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span>
                <span class="n">samples</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span>
                <span class="n">binwidth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">binwidth</span><span class="p">,</span>
                <span class="n">linewidth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">linewidth</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">colorlist</span><span class="p">[</span><span class="nb">id</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Posterior with $n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">$&#39;</span>
                <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;MCMC Sampling density of Posterior Distributions&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">SVI_fitting</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">guide_dist</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the beta/truncnormal curve using parameters trained by SVI.</span>
<span class="sd">        I create plot using PDF given by scipy.stats distributions since torch.dist do not have embedded PDF methods.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># create x axis</span>
        <span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">guide_dist</span><span class="o">==</span><span class="s1">&#39;beta&#39;</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;alpha_q&#39;</span><span class="p">],</span> <span class="n">b</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;beta_q&#39;</span><span class="p">])</span>

        <span class="k">elif</span> <span class="n">guide_dist</span><span class="o">==</span><span class="s1">&#39;normal&#39;</span><span class="p">:</span>

            <span class="c1"># rescale upper/lower bound. See Scipy&#39;s truncnorm doc</span>
            <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">loc</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;loc&#39;</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">]</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower</span> <span class="o">-</span> <span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span><span class="p">,</span> <span class="p">(</span><span class="n">upper</span> <span class="o">-</span> <span class="n">loc</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">truncnorm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="n">b</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;loc&#39;</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">])</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">SVI_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">guide_dist</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">2000</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters as in SVI_run except that data is already defined</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

        <span class="c1"># plot prior</span>
        <span class="n">prior_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">BayesianInferenceClass</span><span class="o">.</span><span class="n">show_prior</span><span class="p">(</span><span class="n">disp_plot</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span>
            <span class="n">data</span><span class="o">=</span><span class="n">prior_sample</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s1">&#39;density&#39;</span><span class="p">,</span>
            <span class="n">binwidth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">binwidth</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#4C4E52&#39;</span><span class="p">,</span>
            <span class="n">linewidth</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">linewidth</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
            <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Prior Distribution&#39;</span>
            <span class="p">)</span>

        <span class="c1"># plot posteriors</span>
        <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_list</span><span class="p">):</span>
            <span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">BayesianInferenceClass</span><span class="o">.</span><span class="n">SVI_run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">guide_dist</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">SVI_fitting</span><span class="p">(</span><span class="n">guide_dist</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">colorlist</span><span class="p">[</span><span class="nb">id</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Posterior with $n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">$&#39;</span>
                <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;SVI density of Posterior Distributions with </span><span class="si">{</span><span class="n">guide_dist</span><span class="si">}</span><span class="s1"> guide&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s set some parameters that we’ll use in all of the examples  below.</p>
<p>To save computer time at first, notice that  we’ll set <code class="docutils literal notranslate"><span class="pre">MCMC_num_samples</span> <span class="pre">=</span> <span class="pre">2000</span></code> and <code class="docutils literal notranslate"><span class="pre">SVI_num_steps</span> <span class="pre">=</span> <span class="pre">5000</span></code>.</p>
<p>(Later, to increase accuracy of approximations, we’ll want to increase these.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">1000</span><span class="p">]</span>
<span class="n">MCMC_num_samples</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">SVI_num_steps</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="c1"># theta is the data generating process</span>
<span class="n">true_theta</span> <span class="o">=</span> <span class="mf">0.8</span>
</pre></div>
</div>
</div>
</div>
<section id="beta-prior-and-posteriors">
<h3><span class="section-number">18.5.1. </span>Beta Prior and Posteriors:<a class="headerlink" href="#beta-prior-and-posteriors" title="Permalink to this heading">#</a></h3>
<p>Let’s compare outcomes when we use a Beta prior.</p>
<p>For the same Beta prior, we shall</p>
<ul class="simple">
<li><p>compute posteriors analytically</p></li>
<li><p>compute posteriors using MCMC  via  <code class="docutils literal notranslate"><span class="pre">Pyro</span></code> and <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code>.</p></li>
<li><p>compute posteriors using  VI via  <code class="docutils literal notranslate"><span class="pre">Pyro</span></code> and <code class="docutils literal notranslate"><span class="pre">Numpyro</span></code>.</p></li>
</ul>
<p>Let’s start with the analytical method that we described in this quantecon lecture <a class="reference external" href="https://python.quantecon.org/prob_meaning.html">https://python.quantecon.org/prob_meaning.html</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First examine Beta priors</span>
<span class="n">BETA_pyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;pyro&#39;</span><span class="p">)</span>
<span class="n">BETA_numpyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>

<span class="n">BETA_pyro_plot</span> <span class="o">=</span> <span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">BETA_pyro</span><span class="p">)</span>
<span class="n">BETA_numpyro_plot</span> <span class="o">=</span> <span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">BETA_numpyro</span><span class="p">)</span>


<span class="c1"># plot analytical Beta prior and posteriors</span>
<span class="n">xaxis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_prior</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="c1"># plot analytical beta prior</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xaxis</span><span class="p">,</span> <span class="n">y_prior</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Analytical Beta Prior&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#4C4E52&#39;</span><span class="p">)</span>

<span class="n">data</span><span class="p">,</span> <span class="n">colorlist</span><span class="p">,</span> <span class="n">N_list</span> <span class="o">=</span> <span class="n">BETA_pyro_plot</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">BETA_pyro_plot</span><span class="o">.</span><span class="n">colorlist</span><span class="p">,</span> <span class="n">BETA_pyro_plot</span><span class="o">.</span><span class="n">N_list</span>
<span class="c1"># plot analytical beta posteriors</span>
<span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N_list</span><span class="p">):</span>
    <span class="n">func</span> <span class="o">=</span> <span class="n">analytical_beta_posterior</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">alpha0</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">beta0</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">y_posterior</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">xaxis</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">xaxis</span><span class="p">,</span> <span class="n">y_posterior</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colorlist</span><span class="p">[</span><span class="nb">id</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Analytical Beta Posterior with $n=</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Analytical Beta Prior and Posterior&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/824261105c17a43fe167ca8dd3dad2b4d8505b490336216f74b743c49e2fabf1.png" src="_images/824261105c17a43fe167ca8dd3dad2b4d8505b490336216f74b743c49e2fabf1.png" />
</div>
</div>
<p>Now let’s use MCMC while still using a beta prior.</p>
<p>We’ll do this for both MCMC and VI.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">BETA_pyro</span><span class="p">)</span><span class="o">.</span><span class="n">MCMC_plot</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">MCMC_num_samples</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">BETA_numpyro</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b34804fdbb42a43fa7dbe298982196b5278ca94168517c824fed28293d2ed3f1.png" src="_images/b34804fdbb42a43fa7dbe298982196b5278ca94168517c824fed28293d2ed3f1.png" />
<img alt="_images/8ea9e3dcc559f5f09fb7bac76d247d4489011c4fd5a1fb2ed5ac951880425b40.png" src="_images/8ea9e3dcc559f5f09fb7bac76d247d4489011c4fd5a1fb2ed5ac951880425b40.png" />
</div>
</div>
<p>Here the MCMC approximation looks good.</p>
<p>But the VI approximation doesn’t look so good.</p>
<ul class="simple">
<li><p>even though we use the  beta distribution as our guide, the VI approximated posterior distributions do not closely resemble the posteriors that we had just computed analytically.</p></li>
</ul>
<p>(Here, our initial parameter for Beta guide is (0.5, 0.5).)</p>
<p>But if we increase the number of  steps from 5000 to 10000 in VI as we now shall do, we’ll get VI-approximated   posteriors
will be  more accurate, as we shall see next.</p>
<p>(Increasing the step size increases computational time though).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">BETA_numpyro</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6e593f3908e9dd084ff150b0d6218aa3f36864501136a49a5747f18b8c784d1e.png" src="_images/6e593f3908e9dd084ff150b0d6218aa3f36864501136a49a5747f18b8c784d1e.png" />
</div>
</div>
</section>
</section>
<section id="non-conjugate-prior-distributions">
<h2><span class="section-number">18.6. </span>Non-conjugate Prior Distributions<a class="headerlink" href="#non-conjugate-prior-distributions" title="Permalink to this heading">#</a></h2>
<p>Having assured ourselves that our MCMC and VI methods can work well when we have  conjugate prior and so can also compute analytically, we
next proceed to situations in which our  prior  is not a beta distribution, so we don’t have a conjugate prior.</p>
<p>So we will have non-conjugate priors and are cast into situations in which we can’t calculate posteriors analytically.</p>
<section id="mcmc">
<h3><span class="section-number">18.6.1. </span>MCMC<a class="headerlink" href="#mcmc" title="Permalink to this heading">#</a></h3>
<p>First, we implement and display  MCMC.</p>
<p>We first initialize the <code class="docutils literal notranslate"><span class="pre">BayesianInference</span></code> classes and then can directly call <code class="docutils literal notranslate"><span class="pre">BayesianInferencePlot</span></code> to plot both MCMC and SVI approximating posteriors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize BayesianInference classes</span>
<span class="c1"># try uniform</span>
<span class="n">STD_UNIFORM_pyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;pyro&#39;</span><span class="p">)</span>
<span class="n">UNIFORM_numpyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.7</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>

<span class="c1"># try truncated lognormal</span>
<span class="n">LOGNORMAL_numpyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;lognormal&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>
<span class="n">LOGNORMAL_pyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;lognormal&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;pyro&#39;</span><span class="p">)</span>

<span class="c1"># try von Mises</span>
<span class="c1"># shifted von Mises</span>
<span class="n">VONMISES_numpyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;vonMises&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>
<span class="c1"># truncated von Mises</span>
<span class="n">VONMISES_pyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;vonMises&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;pyro&#39;</span><span class="p">)</span>

<span class="c1"># try laplace</span>
<span class="n">LAPLACE_numpyro</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;laplace&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uniform</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">STD_UNIFORM_pyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">MCMC_plot</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">MCMC_num_samples</span><span class="p">)</span>

<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">UNIFORM_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">MCMC_plot</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">MCMC_num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0, 1)
Prior Dist: uniform
Solver: pyro
</pre></div>
</div>
<img alt="_images/cc62334462485f265861efedd3ab064b2a5d481873e3d6dfb7ace3590a20a7be.png" src="_images/cc62334462485f265861efedd3ab064b2a5d481873e3d6dfb7ace3590a20a7be.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0.2, 0.7)
Prior Dist: uniform
Solver: numpyro
</pre></div>
</div>
<img alt="_images/2c86523442a8422ae27c5ef3d3037e56085fe9c5fcc8afc20dfbeb4f4ef02bd2.png" src="_images/2c86523442a8422ae27c5ef3d3037e56085fe9c5fcc8afc20dfbeb4f4ef02bd2.png" />
</div>
</div>
<p>In the situation depicted above, we have assumed a  <span class="math notranslate nohighlight">\(Uniform(\underline{\theta}, \overline{\theta})\)</span> prior that puts zero probability   outside a bounded support that excludes the true value.</p>
<p>Consequently,  the posterior cannot put positive probability above <span class="math notranslate nohighlight">\(\overline{\theta}\)</span> or below <span class="math notranslate nohighlight">\(\underline{\theta}\)</span>.</p>
<p>Note how when  the true data-generating <span class="math notranslate nohighlight">\(\theta\)</span> is located at <span class="math notranslate nohighlight">\(0.8\)</span> as it is here,  when <span class="math notranslate nohighlight">\(n\)</span> gets large, the posterior  concentrate on the upper bound of the support of the prior,  <span class="math notranslate nohighlight">\(0.7\)</span> here.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Log Normal</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">LOGNORMAL_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">MCMC_plot</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">MCMC_num_samples</span><span class="p">)</span>

<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">LOGNORMAL_pyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">MCMC_plot</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">MCMC_num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0, 2)
Prior Dist: lognormal
Solver: numpyro
</pre></div>
</div>
<img alt="_images/4b3041c8df7f5863e5a1eee8c88a48bdc7d5f9029f48ddc0b2163e5cf60847f5.png" src="_images/4b3041c8df7f5863e5a1eee8c88a48bdc7d5f9029f48ddc0b2163e5cf60847f5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0, 2)
Prior Dist: lognormal
Solver: pyro
</pre></div>
</div>
<img alt="_images/f226be7eead6cf817dc6bb53dccfb0260dc5c2a3a64a40b0844d175ccacbb769.png" src="_images/f226be7eead6cf817dc6bb53dccfb0260dc5c2a3a64a40b0844d175ccacbb769.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Von Mises</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">VONMISES_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">NOTE: Shifted von Mises&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">MCMC_plot</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">MCMC_num_samples</span><span class="p">)</span>

<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">VONMISES_pyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">NOTE: Truncated von Mises&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">MCMC_plot</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">MCMC_num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: 10
Prior Dist: vonMises
Solver: numpyro

NOTE: Shifted von Mises
</pre></div>
</div>
<img alt="_images/2e8d90e2814e40128660b5db667c4f6f5ce134493ec900ad0bc58c6b6be09389.png" src="_images/2e8d90e2814e40128660b5db667c4f6f5ce134493ec900ad0bc58c6b6be09389.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: 40
Prior Dist: vonMises
Solver: pyro

NOTE: Truncated von Mises
</pre></div>
</div>
<img alt="_images/464aa70aa8c28b12ac5861646ae64e3ad03bb6694f1ff3b3056f69d3475a8d30.png" src="_images/464aa70aa8c28b12ac5861646ae64e3ad03bb6694f1ff3b3056f69d3475a8d30.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Laplace</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">LAPLACE_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">MCMC_plot</span><span class="p">(</span><span class="n">num_samples</span><span class="o">=</span><span class="n">MCMC_num_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0.5, 0.07)
Prior Dist: laplace
Solver: numpyro
</pre></div>
</div>
<img alt="_images/e4f9b94712fa5f67a953187725f638b892811cdcaa7de3b088f749f44fb727cc.png" src="_images/e4f9b94712fa5f67a953187725f638b892811cdcaa7de3b088f749f44fb727cc.png" />
</div>
</div>
<p>To get more accuracy we will now increase the number of steps for Variational Inference (VI)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SVI_num_steps</span> <span class="o">=</span> <span class="mi">50000</span>
</pre></div>
</div>
</div>
</div>
<section id="vi-with-a-truncated-normal-guide">
<h4><span class="section-number">18.6.1.1. </span>VI with a  Truncated Normal Guide<a class="headerlink" href="#vi-with-a-truncated-normal-guide" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uniform</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">BayesianInference</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">name_dist</span><span class="o">=</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;numpyro&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0, 1)
Prior Dist: uniform
Solver: numpyro
</pre></div>
</div>
<img alt="_images/3aaa7d243c627edaf39ed28be93eed089dbe6f1de1db6d96af6c402fe1ada6b3.png" src="_images/3aaa7d243c627edaf39ed28be93eed089dbe6f1de1db6d96af6c402fe1ada6b3.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Log Normal</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">LOGNORMAL_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0, 2)
Prior Dist: lognormal
Solver: numpyro
</pre></div>
</div>
<img alt="_images/625ea8aa0764822e81d801988d84cd6093db859c6abfbb15f28181c38e8ce1af.png" src="_images/625ea8aa0764822e81d801988d84cd6093db859c6abfbb15f28181c38e8ce1af.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Von Mises</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">VONMISES_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">NB: Shifted von Mises&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: 10
Prior Dist: vonMises
Solver: numpyro

NB: Shifted von Mises
</pre></div>
</div>
<img alt="_images/53f5315646ef8bd455e724cc857a325ff8528e7d2d843ac0e2d9b6eb7d58f1f7.png" src="_images/53f5315646ef8bd455e724cc857a325ff8528e7d2d843ac0e2d9b6eb7d58f1f7.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Laplace</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">LAPLACE_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0.5, 0.07)
Prior Dist: laplace
Solver: numpyro
</pre></div>
</div>
<img alt="_images/2aedd58a07a4d20db1d9bb14665b69a1e98fee61d811b2c9a3b74ab2ca703a9b.png" src="_images/2aedd58a07a4d20db1d9bb14665b69a1e98fee61d811b2c9a3b74ab2ca703a9b.png" />
</div>
</div>
</section>
<section id="variational-inference-with-a-beta-guide-distribution">
<h4><span class="section-number">18.6.1.2. </span>Variational Inference with a  Beta Guide Distribution<a class="headerlink" href="#variational-inference-with-a-beta-guide-distribution" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Uniform</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">STD_UNIFORM_pyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0, 1)
Prior Dist: uniform
Solver: pyro
</pre></div>
</div>
<img alt="_images/990218949175f11b1a75131d61ebbc60bd7eeea8fe09d655988a4aa2f16e7253.png" src="_images/990218949175f11b1a75131d61ebbc60bd7eeea8fe09d655988a4aa2f16e7253.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Log Normal</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">LOGNORMAL_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>

<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">LOGNORMAL_pyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0, 2)
Prior Dist: lognormal
Solver: numpyro
</pre></div>
</div>
<img alt="_images/a08129beb7ea9349a70db0573c8ee0aa9130a3074dfa0f116d42522b95bba3e6.png" src="_images/a08129beb7ea9349a70db0573c8ee0aa9130a3074dfa0f116d42522b95bba3e6.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0, 2)
Prior Dist: lognormal
Solver: pyro
</pre></div>
</div>
<img alt="_images/63bd5c545e1ae027986d420b023ffcaea0320b0cda04e81b7d60329be7efe2ef.png" src="_images/63bd5c545e1ae027986d420b023ffcaea0320b0cda04e81b7d60329be7efe2ef.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Von Mises</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">VONMISES_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">NB: Shifted von Mises&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>

<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">VONMISES_pyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">NB: Truncated von Mises&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: 10
Prior Dist: vonMises
Solver: numpyro

NB: Shifted von Mises
</pre></div>
</div>
<img alt="_images/eaa5ee3be9446360a1d308a56436dc93b273dabec7af221cd357f2b22077a1f9.png" src="_images/eaa5ee3be9446360a1d308a56436dc93b273dabec7af221cd357f2b22077a1f9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: 40
Prior Dist: vonMises
Solver: pyro

NB: Truncated von Mises
</pre></div>
</div>
<img alt="_images/db1aed6354cbb57c62881b55022d33f6c7cf6177305162e4cec8c7120122007f.png" src="_images/db1aed6354cbb57c62881b55022d33f6c7cf6177305162e4cec8c7120122007f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Laplace</span>
<span class="n">example_CLASS</span> <span class="o">=</span> <span class="n">LAPLACE_numpyro</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=======INFO=======</span><span class="se">\n</span><span class="s1">Parameters: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">param</span><span class="si">}</span><span class="se">\n</span><span class="s1">Prior Dist: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">name_dist</span><span class="si">}</span><span class="se">\n</span><span class="s1">Solver: </span><span class="si">{</span><span class="n">example_CLASS</span><span class="o">.</span><span class="n">solver</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">BayesianInferencePlot</span><span class="p">(</span><span class="n">true_theta</span><span class="p">,</span> <span class="n">num_list</span><span class="p">,</span> <span class="n">example_CLASS</span><span class="p">)</span><span class="o">.</span><span class="n">SVI_plot</span><span class="p">(</span><span class="n">guide_dist</span><span class="o">=</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="n">SVI_num_steps</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=======INFO=======
Parameters: (0.5, 0.07)
Prior Dist: laplace
Solver: numpyro
</pre></div>
</div>
<img alt="_images/cbd20f0ce26a06ada120aeaf6688dc62c4eeec858ad048783c8fa371ced49670.png" src="_images/cbd20f0ce26a06ada120aeaf6688dc62c4eeec858ad048783c8fa371ced49670.png" />
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tools and Techniques
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="sir_model.html">
   1. Modeling COVID 19
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_algebra.html">
   2. Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="qr_decomp.html">
   3. QR Decomposition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="eig_circulant.html">
   4. Circulant Matrices
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="svd_intro.html">
   5. Singular Value Decomposition (SVD)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="var_dmd.html">
   6. VARs and DMDs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="newton_method.html">
   7. Using Newton’s Method to Solve Economic Models
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Elementary Statistics
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="prob_matrix.html">
   8. Elementary Probability with Matrices
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="stats_examples.html">
   9. Some Probability Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lln_clt.html">
   10. LLN and CLT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="prob_meaning.html">
   11. Two Meanings of Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multi_hyper.html">
   12. Multivariate Hypergeometric Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multivariate_normal.html">
   13. Multivariate Normal Distribution
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hoist_failure.html">
   14. Fault Tree Uncertainties
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="back_prop.html">
   15. Introduction to Artificial Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rand_resp.html">
   16. Randomized Response Surveys
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="util_rand_resp.html">
   17. Expected Utilities of Random Responses
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bayes Law
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   18. Non-Conjugate Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ar1_bayes.html">
   19. Posterior Distributions for  AR(1) Parameters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ar1_turningpts.html">
   20. Forecasting  an AR(1) Process
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Statistics and Information
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="divergence_measures.html">
   21. Statistical Divergence Measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="likelihood_ratio_process.html">
   22. Likelihood Ratio Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="likelihood_ratio_process_2.html">
   23. Heterogeneous Beliefs and Financial Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="likelihood_var.html">
   24. Likelihood Processes for VAR Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="imp_sample.html">
   25. Mean of a Likelihood Ratio Process
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wald_friedman.html">
   26. A Problem that Stumped Milton Friedman
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wald_friedman_2.html">
   27. A Bayesian Formulation of Friedman and Wald’s Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="exchangeable.html">
   28. Exchangeability and Bayesian Updating
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="likelihood_bayes.html">
   29. Likelihood Ratio Processes and Bayesian Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mix_model.html">
   30. Incorrect Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="navy_captain.html">
   31. Bayesian versus Frequentist Decision Rules
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Linear Programming
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="opt_transport.html">
   32. Optimal Transport
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="von_neumann_model.html">
   33. Von Neumann Growth Model (and a Generalization)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction to Dynamics
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="finite_markov.html">
   34. Finite Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="inventory_dynamics.html">
   35. Inventory Dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="linear_models.html">
   36. Linear State Space Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="samuelson.html">
   37. Samuelson Multiplier-Accelerator
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kesten_processes.html">
   38. Kesten Processes and Firm Dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wealth_dynamics.html">
   39. Wealth Distribution Dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kalman.html">
   40. A First Look at the Kalman Filter
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kalman_2.html">
   41. Another Look at the Kalman Filter
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Search
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_model.html">
   42. Job Search I: The McCall Search Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_model_with_separation.html">
   43. Job Search II: Search and Separation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_fitted_vfi.html">
   44. Job Search III: Fitted Value Function Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_correlated.html">
   45. Job Search IV: Correlated Wage Offers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="career.html">
   46. Job Search V: Modeling Career Choice
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="jv.html">
   47. Job Search VI: On-the-Job Search
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mccall_q.html">
   48. Job Search VII: A McCall Worker Q-Learns
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="odu.html">
   49. Job Search VII: Search with Learning
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Consumption, Savings and Capital
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="cass_koopmans_1.html">
   50. Cass-Koopmans Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cass_koopmans_2.html">
   51. Cass-Koopmans Competitive Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cass_fiscal.html">
   52. Cass-Koopmans Model with Distorting Taxes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cass_fiscal_2.html">
   53. Two-Country Model with Distorting Taxes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ak2.html">
   54. Transitions in an Overlapping Generations Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cake_eating_problem.html">
   55. Cake Eating I: Introduction to Optimal Saving
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cake_eating_numerical.html">
   56. Cake Eating II: Numerical Methods
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optgrowth.html">
   57. Optimal Growth I: The Stochastic Optimal Growth Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optgrowth_fast.html">
   58. Optimal Growth II: Accelerating the Code with Numba
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coleman_policy_iter.html">
   59. Optimal Growth III: Time Iteration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="egm_policy_iter.html">
   60. Optimal Growth IV: The Endogenous Grid Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ifp.html">
   61. The Income Fluctuation Problem I: Basic Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ifp_advanced.html">
   62. The Income Fluctuation Problem II: Stochastic Returns on Assets
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  LQ Control
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lqcontrol.html">
   63. LQ Control: Foundations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lagrangian_lqdp.html">
   64. Lagrangian for LQ Control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cross_product_trick.html">
   65. Eliminating Cross Products
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="perm_income.html">
   66. The Permanent Income Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="perm_income_cons.html">
   67. Permanent Income II: LQ Techniques
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lq_inventories.html">
   68. Production Smoothing via Inventories
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Multiple Agent Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lake_model.html">
   69. A Lake Model of Employment and Unemployment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rational_expectations.html">
   70. Rational Expectations Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="re_with_feedback.html">
   71. Stability in Linear Rational Expectations Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markov_perf.html">
   72. Markov Perfect Equilibrium
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="uncertainty_traps.html">
   73. Uncertainty Traps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="aiyagari.html">
   74. The Aiyagari Model
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Asset Pricing and Finance
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="markov_asset.html">
   75. Asset Pricing: Finite State Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ge_arrow.html">
   76. Competitive Equilibria with Arrow Securities
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="harrison_kreps.html">
   77. Heterogeneous Beliefs and Bubbles
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data and Empirics
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="pandas_panel.html">
   78. Pandas for Panel Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ols.html">
   79. Linear Regression in Python
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mle.html">
   80. Maximum Likelihood Estimation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Auctions
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="two_auctions.html">
   81. First-Price and Second-Price Auctions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="house_auction.html">
   82. Multiple Good Allocation Mechanisms
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   83. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   84. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="status.html">
   85. Execution Statistics
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                </ul>

                <ul class="qe-toolbar__links">
                    <li class="btn__search">
                        <form action="search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" accesskey="k">
                            <i data-feather="search" id="search-icon"></i>
                        </form>
                    </li>
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="/_notebooks/bayes_nonconj.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li class="download-pdf" id="downloadButton"><i data-feather="file"></i></li>
                    <!--
                    # Enable if looking for link to specific document hosted on GitHub
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python.myst/blob/main/lectures/bayes_nonconj.md" download><i data-feather="github"></i></a></li>
                    -->
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python.myst" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="/_pdf/quantecon-python.pdf" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://colab.research.google.com/github/QuantEcon/lecture-python.notebooks/blob/main/bayes_nonconj.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-python.notebooks" data-urlpath="tree/lecture-python.notebooks/bayes_nonconj.ipynb" data-branch=main>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://colab.research.google.com/github/QuantEcon/lecture-python.notebooks/blob/main/bayes_nonconj.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "bayes_nonconj";
                const repoURL = "https://github.com/QuantEcon/lecture-python.notebooks";
                const urlPath = "tree/lecture-python.notebooks/bayes_nonconj.ipynb";
                const branch = "main"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>